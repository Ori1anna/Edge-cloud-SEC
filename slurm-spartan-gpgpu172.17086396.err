/data/gpfs/projects/punim2341/jiajunlu/conda/envs/sec-gpu/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
[nltk_data] Downloading package wordnet to /home/jiajunlu/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
[nltk_data] Downloading package omw-1.4 to /home/jiajunlu/nltk_data...
[nltk_data]   Package omw-1.4 is already up-to-date!
INFO:__main__:Loading unified manifest from data/processed/mer2024/manifest_audio_text_augmented_v5.json
INFO:__main__:Loaded 332 samples from unified manifest
INFO:__main__:Processing 332 samples with CPU-limited edge + GPU cloud speculative decoding
INFO:__main__:Caption type: audio_only
INFO:__main__:Language: english
INFO:__main__:Prompt type: detailed
INFO:__main__:Entropy threshold: 3.5
INFO:__main__:K (draft tokens): 5
INFO:__main__:Edge hardware limits: 2 cores, 16.0GB memory
INFO:__main__:Cloud device: GPU (G100)
INFO:__main__:Hardware Limiter initialized:
INFO:__main__:  Original CPU cores: 64
INFO:__main__:  Original memory: 1006.9GB
INFO:__main__:  Limited CPU cores: 2
INFO:__main__:  Limited memory: 16.0GB
INFO:__main__:Edge device: cpu
INFO:__main__:Cloud device: cuda
INFO:__main__:Initializing LimitedEdgeModel with device=cpu, dtype=float32
INFO:src.models.edge_model:Initializing EdgeModel with model_name=Qwen/Qwen2.5-Omni-3B, device=cpu, dtype=float32
INFO:src.models.edge_model:Loading edge model: Qwen/Qwen2.5-Omni-3B
INFO:src.models.edge_model:This may take several minutes for the first time...
INFO:src.models.edge_model:Loading processor...
You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
INFO:src.models.edge_model:Processor loaded successfully
INFO:src.models.edge_model:Loading model (this may take a while)...
Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}
Qwen2_5OmniToken2WavModel does not support eager attention implementation, fall back to sdpa
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.66s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:06<00:03,  3.38s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:07<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:07<00:00,  2.39s/it]
INFO:src.models.edge_model:Edge model loaded successfully
INFO:src.models.edge_model:EdgeModel initialization completed successfully
INFO:__main__:Applied CPU optimizations with 2 threads
INFO:src.models.cloud_model:Loading cloud model: Qwen/Qwen2.5-Omni-7B
INFO:src.models.cloud_model:This may take several minutes for the first time...
INFO:src.models.cloud_model:Loading processor...
INFO:src.models.cloud_model:Processor loaded successfully
INFO:src.models.cloud_model:Loading model (this may take a while)...
Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:06<00:25,  6.38s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:11<00:16,  5.58s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:16<00:10,  5.30s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:21<00:05,  5.16s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:23<00:00,  3.99s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:23<00:00,  4.65s/it]
INFO:src.models.cloud_model:Cloud model loaded successfully
INFO:src.speculative_decoding:Initialized SimpleSpeculativeDecoding with entropy_threshold=3.5, k=5, target_sentences=2, language=chinese, prompt_type=detailed
INFO:__main__:Using prompt template: As an expert in the field of emotions, please focus on the acoustic information in the audio to disc...
INFO:__main__:Processing sample 1/332: sample_00000000
INFO:src.speculative_decoding:Speculative Decoding prompt: ['<|im_start|>system\nYou are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.<|im_end|>\n<|im_start|>user\n<|audio_bos|><|AUDIO|><|audio_eos|>As an expert in the field of emotions, please focus on the acoustic information in the audio to discern clues related to the emotions of the individual. Please provide a detailed description and ultimately predict the emotional state of the individual.<|im_end|>\n<|im_start|>assistant\n']
INFO:src.speculative_decoding:Input keys: ['input_ids', 'attention_mask', 'feature_attention_mask', 'input_features']
INFO:src.speculative_decoding:Audio features shape: torch.Size([1, 128, 30000])
INFO:src.speculative_decoding:Starting speculative decoding with max_new_tokens=128
INFO:src.speculative_decoding:Performing multimodal prefill for efficient incremental generation...
INFO:src.speculative_decoding:Performing multimodal prefill with Edge model...
INFO:src.speculative_decoding:Edge prefill completed in 4.064s
INFO:src.speculative_decoding:Multimodal prefill completed in 4.067s
INFO:src.speculative_decoding:Added stopping criteria for chinese with sentence_end_chars=('。', '.'), min_chars=90, min_new_tokens=48, prompt_type=detailed
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=0/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
WARNING:src.speculative_decoding:Blocking repetition of common English word: 'The'
INFO:src.speculative_decoding:Edge generated 5 tokens: [785, 1697, 4977, 5008, 35118]
INFO:src.speculative_decoding:Token uncertainties: [3.4791622161865234, 2.2164700031280518, 2.1409518718719482, 1.284088134765625, 4.853043079376221]
INFO:src.speculative_decoding:High uncertainty (4.853 > 3.5), calling Cloud for verification
INFO:src.models.cloud_model:Cloud correction: accepted 5/5 tokens (all passed)
INFO:src.models.cloud_model:  -> Probabilities: ['0.0793', '0.2208', '0.2325', '0.1178', '0.0384']
INFO:src.speculative_decoding:Cloud accepted all 5 tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=5, check_sequence_len=185
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=5/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [13, 10964, 16232, 374, 14400]
INFO:src.speculative_decoding:Token uncertainties: [1.6895653009414673, 2.4490232467651367, 1.9185459613800049, 1.2733855247497559, 3.1391210556030273]
WARNING:src.speculative_decoding:Language mismatch detected: expecting Chinese but generated English text
WARNING:src.speculative_decoding:Draft text: . Their tone is somewhat...
WARNING:src.speculative_decoding:Forcing cloud verification to correct language
INFO:src.speculative_decoding:High uncertainty (3.700 > 3.5), calling Cloud for verification
INFO:src.models.cloud_model:Cloud correction: accepted 5/5 tokens (all passed)
INFO:src.models.cloud_model:  -> Probabilities: ['0.1796', '0.1779', '0.1914', '0.7415', '0.1234']
INFO:src.speculative_decoding:Cloud accepted all 5 tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=10, check_sequence_len=190
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=10/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [70460, 979, 807, 1977, 330]
INFO:src.speculative_decoding:Token uncertainties: [2.5444231033325195, 1.2721381187438965, 1.5076768398284912, 0.4705263078212738, 1.354881763458252]
WARNING:src.speculative_decoding:Language mismatch detected: expecting Chinese but generated English text
WARNING:src.speculative_decoding:Draft text:  hesitant when they say "...
WARNING:src.speculative_decoding:Forcing cloud verification to correct language
INFO:src.speculative_decoding:High uncertainty (3.700 > 3.5), calling Cloud for verification
INFO:src.models.cloud_model:Cloud correction: accepted 5/5 tokens (all passed)
INFO:src.models.cloud_model:  -> Probabilities: ['0.7596', '0.0068', '0.6711', '0.9582', '0.9607']
INFO:src.speculative_decoding:Cloud accepted all 5 tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=15, check_sequence_len=195
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=15/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [35946, 99459, 99392, 103924, 1]
INFO:src.speculative_decoding:Token uncertainties: [0.7806749939918518, 0.6323063969612122, 0.041460681706666946, 0.2510654628276825, 1.1537630558013916]
INFO:src.speculative_decoding:Low uncertainty (1.154 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=20, check_sequence_len=200
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=20/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [3837, 8206, 46918, 17267, 438]
INFO:src.speculative_decoding:Token uncertainties: [1.4140037298202515, 2.8806328773498535, 2.447845697402954, 0.3541516959667206, 0.5110021233558655]
INFO:src.speculative_decoding:Low uncertainty (2.881 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=25, check_sequence_len=205
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=25/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [364, 40, 1513, 944, 1414]
INFO:src.speculative_decoding:Token uncertainties: [0.37021827697753906, 0.22417058050632477, 0.24467253684997559, 0.021625783294439316, 0.1421053111553192]
INFO:src.speculative_decoding:Low uncertainty (0.370 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=30, check_sequence_len=210
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=30/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [4427, 1096, 13230, 429, 1052]
INFO:src.speculative_decoding:Token uncertainties: [2.474355936050415, 2.338731288909912, 2.7281949520111084, 1.1627118587493896, 0.6118156909942627]
WARNING:src.speculative_decoding:Language mismatch detected: expecting Chinese but generated English text
WARNING:src.speculative_decoding:Draft text: '. This suggests that there...
WARNING:src.speculative_decoding:Forcing cloud verification to correct language
INFO:src.speculative_decoding:High uncertainty (3.700 > 3.5), calling Cloud for verification
INFO:src.models.cloud_model:Cloud correction: accepted 5/5 tokens (all passed)
INFO:src.models.cloud_model:  -> Probabilities: ['0.1964', '0.1252', '0.3898', '0.0086', '0.0168']
INFO:src.speculative_decoding:Cloud accepted all 5 tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=35, check_sequence_len=215
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=35/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
WARNING:src.speculative_decoding:Blocking repetition of common English word: ' or'
INFO:src.speculative_decoding:Edge generated 5 tokens: [594, 1045, 10492, 476, 26826]
INFO:src.speculative_decoding:Token uncertainties: [1.3016074895858765, 0.5829368233680725, 2.7685203552246094, 0.7403615713119507, 2.490870475769043]
WARNING:src.speculative_decoding:Language mismatch detected: expecting Chinese but generated English text
WARNING:src.speculative_decoding:Draft text: 's some doubt or uncertainty...
WARNING:src.speculative_decoding:Forcing cloud verification to correct language
INFO:src.speculative_decoding:High uncertainty (3.700 > 3.5), calling Cloud for verification
INFO:src.models.cloud_model:Cloud correction: accepted 5/5 tokens (all passed)
INFO:src.models.cloud_model:  -> Probabilities: ['0.7079', '0.0997', '0.4414', '0.9459', '0.0925']
INFO:src.speculative_decoding:Cloud accepted all 5 tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=40, check_sequence_len=220
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=40/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
WARNING:src.speculative_decoding:Blocking repetition of common English word: ' in'
INFO:src.speculative_decoding:Edge generated 5 tokens: [304, 862, 3971, 13, 2379]
INFO:src.speculative_decoding:Token uncertainties: [1.5913059711456299, 0.6213725805282593, 2.1344120502471924, 0.6747484803199768, 3.254767417907715]
INFO:src.speculative_decoding:Low uncertainty (3.255 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=45, check_sequence_len=225
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=45/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [1083, 6286, 537, 3432, 3139]
INFO:src.speculative_decoding:Token uncertainties: [1.0201441049575806, 1.9785486459732056, 1.8556777238845825, 0.017237570136785507, 1.969411849975586]
WARNING:src.speculative_decoding:Language mismatch detected: expecting Chinese but generated English text
WARNING:src.speculative_decoding:Draft text:  also mention not having experience...
WARNING:src.speculative_decoding:Forcing cloud verification to correct language
INFO:src.speculative_decoding:High uncertainty (3.700 > 3.5), calling Cloud for verification
INFO:src.models.cloud_model:Cloud correction: accepted 5/5 tokens (all passed)
INFO:src.models.cloud_model:  -> Probabilities: ['0.7625', '0.5935', '0.4141', '0.9977', '0.2159']
INFO:src.speculative_decoding:Cloud accepted all 5 tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=50, check_sequence_len=230
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=50/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [11, 892, 4623, 14807, 264]
INFO:src.speculative_decoding:Token uncertainties: [0.8580759763717651, 2.364384174346924, 2.18501877784729, 2.2736055850982666, 1.8705538511276245]
WARNING:src.speculative_decoding:Language mismatch detected: expecting Chinese but generated English text
WARNING:src.speculative_decoding:Draft text: , which further indicates a...
WARNING:src.speculative_decoding:Forcing cloud verification to correct language
INFO:src.speculative_decoding:High uncertainty (3.700 > 3.5), calling Cloud for verification
INFO:src.models.cloud_model:Cloud correction: accepted 5/5 tokens (all passed)
INFO:src.models.cloud_model:  -> Probabilities: ['0.1030', '0.8000', '0.4268', '0.4315', '0.6248']
INFO:src.speculative_decoding:Cloud accepted all 5 tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=55, check_sequence_len=235
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=55/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
WARNING:src.speculative_decoding:Blocking repetition of common English word: ' of'
INFO:src.speculative_decoding:Edge generated 5 tokens: [6853, 315, 12136, 13, 27893]
INFO:src.speculative_decoding:Token uncertainties: [0.44304439425468445, 0.0015918860444799066, 1.2748464345932007, 1.2114511728286743, 2.1567490100860596]
INFO:src.speculative_decoding:Low uncertainty (2.157 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=60, check_sequence_len=240
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=60/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
WARNING:src.speculative_decoding:Blocking repetition of common English word: ' the'
INFO:src.speculative_decoding:Edge generated 5 tokens: [358, 4172, 7023, 279, 3842]
INFO:src.speculative_decoding:Token uncertainties: [0.016638481989502907, 0.8888506889343262, 0.5686829090118408, 1.1492279767990112, 1.1949013471603394]
INFO:src.speculative_decoding:Low uncertainty (1.195 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=65, check_sequence_len=245
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=65/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
WARNING:src.speculative_decoding:Blocking repetition of common English word: ' to'
INFO:src.speculative_decoding:Edge generated 5 tokens: [311, 387, 8266, 74599, 13]
INFO:src.speculative_decoding:Token uncertainties: [1.1670732498168945, 0.12458894401788712, 1.8956186771392822, 2.2769312858581543, 1.5628262758255005]
INFO:src.speculative_decoding:Low uncertainty (2.277 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=70, check_sequence_len=250
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=70/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [3555, 653, 498, 1744, 30]
INFO:src.speculative_decoding:Token uncertainties: [1.7248938083648682, 0.7487432956695557, 0.0002795679320115596, 0.0014229204971343279, 0.9668546915054321]
INFO:src.speculative_decoding:Low uncertainty (1.725 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=75, check_sequence_len=255
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=75/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [3155, 498, 614, 894, 1008]
INFO:src.speculative_decoding:Token uncertainties: [1.0247184038162231, 0.0030416310764849186, 1.0918726921081543, 0.31227731704711914, 0.9476833939552307]
WARNING:src.speculative_decoding:Language mismatch detected: expecting Chinese but generated English text
WARNING:src.speculative_decoding:Draft text:  Do you have any other...
WARNING:src.speculative_decoding:Forcing cloud verification to correct language
INFO:src.speculative_decoding:High uncertainty (3.700 > 3.5), calling Cloud for verification
INFO:src.models.cloud_model:Cloud correction: accepted 5/5 tokens (all passed)
INFO:src.models.cloud_model:  -> Probabilities: ['0.7733', '0.9997', '0.7927', '0.9411', '0.9315']
INFO:src.speculative_decoding:Cloud accepted all 5 tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=80, check_sequence_len=260
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=80/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
WARNING:src.speculative_decoding:Blocking repetition of common English word: ' on'
INFO:src.speculative_decoding:Edge generated 5 tokens: [11303, 389, 419, 30, 151645]
INFO:src.speculative_decoding:Token uncertainties: [2.9725606441497803, 0.8655297756195068, 0.8092527389526367, 1.055076241493225, 0.0022856586147099733]
INFO:src.speculative_decoding:Low uncertainty (2.973 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Stop condition met in accepted token 151645, stopping generation
INFO:src.speculative_decoding:Speculative decoding completed: 85 tokens, 8 cloud calls, 0 corrections
INFO:absl:Using default tokenizer.
INFO:__main__:Sample 1:
INFO:__main__:  Reference: In the audio, the character's tone is initially raised, expressing dissatisfaction and impatience. This may indicate that he is discussing a serious issue and already feeling a bit frustrated. This change suggests that the speaker has lightened the tense topic through jokes and banter. In the audio, the character's tone is initially raised, expressing dissatisfaction and impatience. Later, while laughing, the character speaks, conveying happiness with a hint of teasing. I, I, I don't have any experience in this area." This sentence could be the male doctor's response or explanation to a certain question. Audio, from dissatisfaction and impatience to happiness with a hint of teasing, we can infer that this sentence may have a humorous or self-deprecating tone. The male doctor lightens the tense topic through jokes and banter, displaying a relaxed and happy mood.
INFO:__main__:  Generated: The person seems quite uncertain. Their tone is somewhat hesitant when they say "我哪知道啊"，which translates roughly as 'I don't know'. This suggests that there's some doubt or uncertainty in their mind. They also mention not having experience, which further indicates a lack of confidence. Overall I'd predict the individual to be feeling doubtful. What do you think? Do you have any other thoughts on this?
INFO:__main__:  BLEU-1: 0.1363
INFO:__main__:  BLEU-4: 0.0095
INFO:__main__:  METEOR: 0.0703
INFO:__main__:  ROUGE-L: 0.1244
INFO:__main__:  CIDEr: 0.0000
INFO:__main__:  BERTScore: Computing in batch...
INFO:__main__:  Cloud calls: 8
INFO:__main__:  Acceptance rate: 1.000
INFO:__main__:  Cloud call rate: 0.444
INFO:__main__:  TTFT: 7.1338s
INFO:__main__:  Total Time: 28.8170s
INFO:__main__:  CPU Usage: 187.1% (max: 209.7%)
INFO:__main__:  Memory Usage: 23.70GB (max: 23.75GB)
INFO:__main__:
INFO:__main__:Processing sample 2/332: sample_00000007
INFO:src.speculative_decoding:Speculative Decoding prompt: ['<|im_start|>system\nYou are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.<|im_end|>\n<|im_start|>user\n<|audio_bos|><|AUDIO|><|audio_eos|>As an expert in the field of emotions, please focus on the acoustic information in the audio to discern clues related to the emotions of the individual. Please provide a detailed description and ultimately predict the emotional state of the individual.<|im_end|>\n<|im_start|>assistant\n']
INFO:src.speculative_decoding:Input keys: ['input_ids', 'attention_mask', 'feature_attention_mask', 'input_features']
INFO:src.speculative_decoding:Audio features shape: torch.Size([1, 128, 30000])
INFO:src.speculative_decoding:Starting speculative decoding with max_new_tokens=128
INFO:src.speculative_decoding:Performing multimodal prefill for efficient incremental generation...
INFO:src.speculative_decoding:Performing multimodal prefill with Edge model...
INFO:src.speculative_decoding:Edge prefill completed in 4.778s
INFO:src.speculative_decoding:Multimodal prefill completed in 4.783s
INFO:src.speculative_decoding:Added stopping criteria for chinese with sentence_end_chars=('。', '.'), min_chars=90, min_new_tokens=48, prompt_type=detailed
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=0/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
WARNING:src.speculative_decoding:Blocking repetition of common English word: 'The'
INFO:src.speculative_decoding:Edge generated 5 tokens: [785, 1697, 4977, 5008, 6247]
INFO:src.speculative_decoding:Token uncertainties: [3.7833359241485596, 2.8121578693389893, 2.026155710220337, 1.0891361236572266, 2.8524482250213623]
INFO:src.speculative_decoding:High uncertainty (3.783 > 3.5), calling Cloud for verification
INFO:src.models.cloud_model:Cloud correction: accepted 5/5 tokens (all passed)
INFO:src.models.cloud_model:  -> Probabilities: ['0.0437', '0.1288', '0.2543', '0.0684', '0.2141']
INFO:src.speculative_decoding:Cloud accepted all 5 tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=5, check_sequence_len=216
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=5/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
WARNING:src.speculative_decoding:Blocking repetition of common English word: ' The'
INFO:src.speculative_decoding:Edge generated 5 tokens: [13, 576, 16232, 374, 70314]
INFO:src.speculative_decoding:Token uncertainties: [1.379328966140747, 2.2858340740203857, 3.308751344680786, 1.1087249517440796, 2.9043285846710205]
WARNING:src.speculative_decoding:Language mismatch detected: expecting Chinese but generated English text
WARNING:src.speculative_decoding:Draft text: . The tone is cheerful...
WARNING:src.speculative_decoding:Forcing cloud verification to correct language
INFO:src.speculative_decoding:High uncertainty (3.700 > 3.5), calling Cloud for verification
INFO:src.models.cloud_model:Cloud correction: accepted 5/5 tokens (all passed)
INFO:src.models.cloud_model:  -> Probabilities: ['0.5817', '0.2640', '0.2689', '0.1230', '0.0534']
INFO:src.speculative_decoding:Cloud accepted all 5 tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=10, check_sequence_len=221
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=10/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [11, 1075, 807, 2299, 3330]
INFO:src.speculative_decoding:Token uncertainties: [0.933204710483551, 2.6702401638031006, 2.1852829456329346, 1.1137553453445435, 2.962925672531128]
INFO:src.speculative_decoding:Low uncertainty (2.963 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=15, check_sequence_len=226
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=15/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
WARNING:src.speculative_decoding:Blocking repetition of common English word: ' to'
INFO:src.speculative_decoding:Edge generated 5 tokens: [4637, 311, 2494, 13, 2619]
INFO:src.speculative_decoding:Token uncertainties: [0.015134649351239204, 0.08290839940309525, 1.6991302967071533, 2.4452767372131348, 2.6233956813812256]
INFO:src.speculative_decoding:Low uncertainty (2.623 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=20, check_sequence_len=231
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=20/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
WARNING:src.speculative_decoding:Blocking repetition of common English word: ' an'
INFO:src.speculative_decoding:Edge generated 5 tokens: [594, 458, 84673, 4271, 311]
INFO:src.speculative_decoding:Token uncertainties: [0.7512032389640808, 1.1953518390655518, 3.619255542755127, 2.364895820617676, 0.6319049000740051]
INFO:src.speculative_decoding:High uncertainty (3.619 > 3.5), calling Cloud for verification
INFO:src.models.cloud_model:Cloud correction: accepted 5/5 tokens (all passed)
INFO:src.models.cloud_model:  -> Probabilities: ['0.8481', '0.0227', '0.3156', '0.4524', '0.6847']
INFO:src.speculative_decoding:Cloud accepted all 5 tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=25, check_sequence_len=236
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=25/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [862, 8806, 11, 892, 5990]
INFO:src.speculative_decoding:Token uncertainties: [0.9321513772010803, 1.2826404571533203, 2.0368943214416504, 2.468427896499634, 2.6938233375549316]
INFO:src.speculative_decoding:Low uncertainty (2.694 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=30, check_sequence_len=241
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=30/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [14807, 6785, 15650, 13, 2055]
INFO:src.speculative_decoding:Token uncertainties: [1.7301734685897827, 1.461476445198059, 0.46981874108314514, 1.4340622425079346, 2.941288709640503]
INFO:src.speculative_decoding:Low uncertainty (2.941 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=35, check_sequence_len=246
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=35/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [358, 4172, 1977, 419, 1697]
INFO:src.speculative_decoding:Token uncertainties: [0.4466964900493622, 0.7893843054771423, 0.8246525526046753, 1.2578697204589844, 0.49696698784828186]
INFO:src.speculative_decoding:Low uncertainty (1.258 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=40, check_sequence_len=251
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=40/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
WARNING:src.speculative_decoding:Blocking repetition of common English word: ' in'
WARNING:src.speculative_decoding:Blocking repetition of common English word: ' a'
INFO:src.speculative_decoding:Edge generated 5 tokens: [374, 304, 264, 1661, 19671]
INFO:src.speculative_decoding:Token uncertainties: [0.25945231318473816, 1.5548123121261597, 0.1189689114689827, 1.049973726272583, 0.8299057483673096]
WARNING:src.speculative_decoding:Language mismatch detected: expecting Chinese but generated English text
WARNING:src.speculative_decoding:Draft text:  is in a good mood...
WARNING:src.speculative_decoding:Forcing cloud verification to correct language
INFO:src.speculative_decoding:High uncertainty (3.700 > 3.5), calling Cloud for verification
INFO:src.models.cloud_model:Cloud correction: accepted 5/5 tokens (all passed)
INFO:src.models.cloud_model:  -> Probabilities: ['0.9816', '0.6593', '0.9762', '0.8070', '0.7649']
INFO:src.speculative_decoding:Cloud accepted all 5 tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=45, check_sequence_len=256
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=45/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [13, 3555, 653, 498, 1744]
INFO:src.speculative_decoding:Token uncertainties: [1.6245990991592407, 0.8189076781272888, 0.668797492980957, 0.00017470611783210188, 0.0024659971240907907]
WARNING:src.speculative_decoding:Language mismatch detected: expecting Chinese but generated English text
WARNING:src.speculative_decoding:Draft text: . What do you think...
WARNING:src.speculative_decoding:Forcing cloud verification to correct language
INFO:src.speculative_decoding:High uncertainty (3.700 > 3.5), calling Cloud for verification
INFO:src.models.cloud_model:Cloud correction: accepted 5/5 tokens (all passed)
INFO:src.models.cloud_model:  -> Probabilities: ['0.5359', '0.9525', '0.8915', '1.0000', '0.9997']
INFO:src.speculative_decoding:Cloud accepted all 5 tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=50, check_sequence_len=261
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=50/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [30, 3155, 498, 614, 894]
INFO:src.speculative_decoding:Token uncertainties: [0.43647313117980957, 1.2278214693069458, 0.005217135883867741, 1.5990463495254517, 0.5735336542129517]
WARNING:src.speculative_decoding:Language mismatch detected: expecting Chinese but generated English text
WARNING:src.speculative_decoding:Draft text: ? Do you have any...
WARNING:src.speculative_decoding:Forcing cloud verification to correct language
INFO:src.speculative_decoding:High uncertainty (3.700 > 3.5), calling Cloud for verification
INFO:src.models.cloud_model:Cloud correction: accepted 5/5 tokens (all passed)
INFO:src.models.cloud_model:  -> Probabilities: ['0.8440', '0.6995', '0.9998', '0.6876', '0.9311']
INFO:src.speculative_decoding:Cloud accepted all 5 tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=55, check_sequence_len=266
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=55/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
WARNING:src.speculative_decoding:Blocking repetition of common English word: ' for'
INFO:src.speculative_decoding:Edge generated 5 tokens: [1008, 7699, 10469, 369, 752]
INFO:src.speculative_decoding:Token uncertainties: [0.7013177871704102, 2.505751848220825, 1.9925261735916138, 1.8718326091766357, 0.21905387938022614]
WARNING:src.speculative_decoding:Language mismatch detected: expecting Chinese but generated English text
WARNING:src.speculative_decoding:Draft text:  other audio samples for me...
WARNING:src.speculative_decoding:Forcing cloud verification to correct language
INFO:src.speculative_decoding:High uncertainty (3.700 > 3.5), calling Cloud for verification
INFO:src.models.cloud_model:Cloud correction: accepted 5/5 tokens (all passed)
INFO:src.models.cloud_model:  -> Probabilities: ['0.9548', '0.2952', '0.4145', '0.1851', '0.6288']
INFO:src.speculative_decoding:Cloud accepted all 5 tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=60, check_sequence_len=271
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=60/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
WARNING:src.speculative_decoding:Blocking repetition of common English word: ' to'
INFO:src.speculative_decoding:Edge generated 5 tokens: [311, 23643, 30, 151645, 198]
INFO:src.speculative_decoding:Token uncertainties: [0.007540547288954258, 0.9740080237388611, 0.011950869113206863, 0.002206526231020689, 1.5895970136625692e-05]
INFO:src.speculative_decoding:Low uncertainty (0.974 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Stop condition met in accepted token 151645, stopping generation
INFO:src.speculative_decoding:Speculative decoding completed: 65 tokens, 7 cloud calls, 0 corrections
INFO:absl:Using default tokenizer.
INFO:__main__:Sample 2:
INFO:__main__:  Reference: In the audio, the character's voice is loud, with a calm tone and a hint of laughter, indicating that the character is in a pleasant mood. In the audio, the character's voice is loud, with a calm tone and a hint of laughter, indicating that the character is in a pleasant mood. Audio, we can infer that this sentence is a positive response from the lady to the other person, indicating her willingness to meet. Therefore, this sentence expresses the lady's happiness and anticipation.
INFO:__main__:  Generated: The person seems quite happy. The tone is cheerful, like they're looking forward to something. There's an upbeat quality to their speech, which usually indicates positive feelings. So I'd say this person is in a good mood. What do you think? Do you have any other audio samples for me to analyze?
INFO:__main__:  BLEU-1: 0.1941
INFO:__main__:  BLEU-4: 0.0145
INFO:__main__:  METEOR: 0.1005
INFO:__main__:  ROUGE-L: 0.1690
INFO:__main__:  CIDEr: 0.0000
INFO:__main__:  BERTScore: Computing in batch...
INFO:__main__:  Cloud calls: 7
INFO:__main__:  Acceptance rate: 1.000
INFO:__main__:  Cloud call rate: 0.500
INFO:__main__:  TTFT: 6.2432s
INFO:__main__:  Total Time: 23.3184s
INFO:__main__:  CPU Usage: 195.6% (max: 209.7%)
INFO:__main__:  Memory Usage: 23.93GB (max: 24.05GB)
INFO:__main__:
INFO:__main__:Processing sample 3/332: sample_00000021
INFO:src.speculative_decoding:Speculative Decoding prompt: ['<|im_start|>system\nYou are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.<|im_end|>\n<|im_start|>user\n<|audio_bos|><|AUDIO|><|audio_eos|>As an expert in the field of emotions, please focus on the acoustic information in the audio to discern clues related to the emotions of the individual. Please provide a detailed description and ultimately predict the emotional state of the individual.<|im_end|>\n<|im_start|>assistant\n']
INFO:src.speculative_decoding:Input keys: ['input_ids', 'attention_mask', 'feature_attention_mask', 'input_features']
INFO:src.speculative_decoding:Audio features shape: torch.Size([1, 128, 30000])
INFO:src.speculative_decoding:Starting speculative decoding with max_new_tokens=128
INFO:src.speculative_decoding:Performing multimodal prefill for efficient incremental generation...
INFO:src.speculative_decoding:Performing multimodal prefill with Edge model...
INFO:src.speculative_decoding:Edge prefill completed in 3.758s
INFO:src.speculative_decoding:Multimodal prefill completed in 3.762s
INFO:src.speculative_decoding:Added stopping criteria for chinese with sentence_end_chars=('。', '.'), min_chars=90, min_new_tokens=48, prompt_type=detailed
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=0/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [45181, 107083, 111268, 100192, 3837]
INFO:src.speculative_decoding:Token uncertainties: [4.6935906410217285, 3.1061840057373047, 1.5176039934158325, 2.5634267330169678, 0.3882295787334442]
INFO:src.speculative_decoding:High uncertainty (4.694 > 3.5), calling Cloud for verification
INFO:src.models.cloud_model:Cloud correction: accepted 5/5 tokens (all passed)
INFO:src.models.cloud_model:  -> Probabilities: ['0.0017', '0.0231', '0.7692', '0.1401', '0.8391']
INFO:src.speculative_decoding:Cloud accepted all 5 tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=5, check_sequence_len=184
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=5/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [104283, 17340, 108876, 20412, 106837]
INFO:src.speculative_decoding:Token uncertainties: [1.8725934028625488, 1.817992925643921, 2.6149778366088867, 2.8080878257751465, 1.667912244796753]
INFO:src.speculative_decoding:Low uncertainty (2.808 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=10, check_sequence_len=189
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=10/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [9370, 1773, 80443, 100687, 105694]
INFO:src.speculative_decoding:Token uncertainties: [0.07584291696548462, 0.3266710937023163, 3.141822576522827, 3.0414416790008545, 2.489731550216675]
INFO:src.speculative_decoding:Low uncertainty (3.142 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=15, check_sequence_len=194
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=15/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [100631, 117911, 105437, 1773, 110098]
INFO:src.speculative_decoding:Token uncertainties: [0.9450398683547974, 2.858424425125122, 1.6405668258666992, 0.6627268195152283, 3.7926888465881348]
INFO:src.speculative_decoding:High uncertainty (3.793 > 3.5), calling Cloud for verification
INFO:src.models.cloud_model:Cloud correction: accepted 5/5 tokens (all passed)
INFO:src.models.cloud_model:  -> Probabilities: ['0.4888', '0.1545', '0.0131', '0.5441', '0.0242']
INFO:src.speculative_decoding:Cloud accepted all 5 tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=20, check_sequence_len=199
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=20/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [49111, 33108, 29490, 18493, 112225]
INFO:src.speculative_decoding:Token uncertainties: [1.8725874423980713, 0.4838493764400482, 0.13432247936725616, 2.6990580558776855, 2.5948503017425537]
INFO:src.speculative_decoding:Low uncertainty (2.699 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=25, check_sequence_len=204
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=25/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [101888, 99557, 30709, 100410, 104080]
INFO:src.speculative_decoding:Token uncertainties: [2.807467460632324, 2.560781240463257, 0.7694898247718811, 0.029524875804781914, 0.8444320559501648]
INFO:src.speculative_decoding:Low uncertainty (2.807 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=30, check_sequence_len=209
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=30/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [103976, 1773, 99999, 104538, 99487]
INFO:src.speculative_decoding:Token uncertainties: [1.9795986413955688, 0.6975246071815491, 3.924154758453369, 2.242292642593384, 2.8057353496551514]
INFO:src.speculative_decoding:High uncertainty (3.924 > 3.5), calling Cloud for verification
INFO:src.models.cloud_model:Cloud correction: accepted 5/5 tokens (all passed)
INFO:src.models.cloud_model:  -> Probabilities: ['0.3228', '0.6165', '0.2026', '0.0248', '0.0231']
INFO:src.speculative_decoding:Cloud accepted all 5 tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=35, check_sequence_len=214
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=35/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [103947, 44091, 104583, 99792, 108056]
INFO:src.speculative_decoding:Token uncertainties: [1.1034469604492188, 2.1903371810913086, 1.4647369384765625, 1.6585127115249634, 1.5727853775024414]
INFO:src.speculative_decoding:Low uncertainty (2.190 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=40, check_sequence_len=219
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=40/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [3837, 16530, 99508, 103386, 99744]
INFO:src.speculative_decoding:Token uncertainties: [1.6275415420532227, 3.324124813079834, 2.34248948097229, 0.5696961879730225, 1.5061559677124023]
INFO:src.speculative_decoding:Low uncertainty (3.324 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=45, check_sequence_len=224
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=45/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [107115, 1773, 56568, 104806, 100626]
INFO:src.speculative_decoding:Token uncertainties: [3.881526470184326, 1.088273286819458, 2.2310538291931152, 0.42864659428596497, 0.45244619250297546]
INFO:src.speculative_decoding:High uncertainty (3.882 > 3.5), calling Cloud for verification
INFO:src.models.cloud_model:Cloud correction: accepted 5/5 tokens (all passed)
INFO:src.models.cloud_model:  -> Probabilities: ['0.3413', '0.3554', '0.4857', '0.9336', '0.9202']
INFO:src.speculative_decoding:Cloud accepted all 5 tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=50, check_sequence_len=229
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=50/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [109909, 105761, 101042, 86119, 3837]
INFO:src.speculative_decoding:Token uncertainties: [1.720870018005371, 0.3793993294239044, 1.1354738473892212, 1.3928303718566895, 0.5204207897186279]
INFO:src.speculative_decoding:Low uncertainty (1.721 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=55, check_sequence_len=234
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=55/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [104570, 114817, 104170, 93, 1773]
INFO:src.speculative_decoding:Token uncertainties: [1.6855430603027344, 0.4070011377334595, 0.5614895224571228, 0.006391861941665411, 0.027862830087542534]
INFO:src.speculative_decoding:Low uncertainty (1.686 <= 3.5), accepting all Edge tokens
INFO:src.speculative_decoding:Checking stopping criteria: generated_tokens=60, check_sequence_len=239
INFO:src.speculative_decoding:Stopping criteria check result: False
INFO:src.speculative_decoding:=== Generation Loop Iteration: generated_tokens=60/128 ===
INFO:src.speculative_decoding:Edge generating 5 draft tokens incrementally...
INFO:src.speculative_decoding:Using incremental generation with KV cache
INFO:src.speculative_decoding:Edge generated 5 tokens: [151645, 198, 151643, 33975, 25]
INFO:src.speculative_decoding:Token uncertainties: [0.0007500398205593228, 2.4131895770551637e-05, 6.557998858625069e-05, 3.7901411056518555, 0.055602625012397766]
INFO:src.speculative_decoding:High uncertainty (3.790 > 3.5), calling Cloud for verification
INFO:src.models.cloud_model:Cloud correction: accepted 5/5 tokens (all passed)
INFO:src.models.cloud_model:  -> Probabilities: ['0.9999', '1.0000', '1.0000', '0.4774', '0.9618']
INFO:src.speculative_decoding:Cloud accepted all 5 tokens
INFO:src.speculative_decoding:Stop condition met in accepted token 151645, stopping generation
INFO:src.speculative_decoding:Speculative decoding completed: 65 tokens, 5 cloud calls, 0 corrections
ERROR:src.evaluation.metrics:Error computing METEOR: could not convert string to float: b'Error: specify SCORE or EVAL or SING'
[2025-10-27T10:17:27.010] error: *** JOB 17086396 ON spartan-gpgpu172 CANCELLED AT 2025-10-27T10:17:27 DUE TO TIME LIMIT ***
