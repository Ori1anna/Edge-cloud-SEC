# è‹±è¯­Cloud Baselineé—®é¢˜åˆ†æ

## ğŸ› å‘ç°çš„é—®é¢˜

### é—®é¢˜1: **ç”Ÿæˆäº†å¯¹è¯å¼å†…å®¹**ï¼ˆä¸¥é‡ï¼‰

#### æ ·æœ¬è¯æ®

**Sample 00000000**:
```
"The voice is steady but carries a tone of uncertainty and hesitation. It sounds like the speaker is trying to reassure someone or explain something without much confidence. What do you think might be causing this emotion?"
                                                                                                    â†‘ âŒ å¯¹è¯å¼ç»“å°¾
```

**Sample 00000021**:
```
"The woman's tone is steady and clear, conveying confidence and determination. It sounds like she is fully committed to being with Xiao Chuan. What do you think about this?"
                                                                                                                              â†‘ âŒ å¯¹è¯å¼ç»“å°¾
```

**Sample 00000070**:
```
"The man's tone is calm but carries a subtle hint of skepticism. It's like he's questioning something important without showing his true feelings openly. What do you think might be causing this skepticism?"
                                                                                                                                â†‘ âŒ å¯¹è¯å¼ç»“å°¾
```

**ç»Ÿè®¡**: 10ä¸ªæ ·æœ¬ä¸­è‡³å°‘5ä¸ªä»¥"What do you think..."ç»“å°¾

---

### é—®é¢˜2: **Reference captionè´¨é‡æå·®**ï¼ˆä¸¥é‡ï¼‰

#### æ ·æœ¬è¯æ®

**Sample 00000000 Reference**:
```
"In the audio, the character's tone is initially raised, expressing dissatisfaction and impatience. This may indicate that he is discussing a serious issue and already feeling a bit frustrated. This change suggests that the speaker has lightened the tense topic through jokes and banter. In the audio, the character's tone is initially raised, expressing dissatisfaction and impatience. Later, while laughing, the character speaks, conveying happiness with a hint of teasing. I, I, I don't have any experience in this area.\" This sentence could be the male doctor's response or explanation to a certain question. Audio, from dissatisfaction and impatience to happiness with a hint of teasing, we can infer that this sentence may have a humorous or self-deprecating tone. The male doctor lightens the tense topic through jokes and banter, displaying a relaxed and happy mood."
```

**é—®é¢˜**:
1. âŒ **å¥å­é‡å¤**: "In the audio, the character's tone is initially raised..." å‡ºç°äº†2æ¬¡
2. âŒ **åŒ…å«å­—å¹•**: "I, I, I don't have any experience in this area.\""
3. âŒ **è¯­æ³•é”™è¯¯**: "Audio, from dissatisfaction..." ç¼ºå°‘ä¸»è¯­
4. âŒ **å¥å­ç ´ç¢**: å¤šä¸ªå¥å­æ‹¼æ¥ä¸è‡ªç„¶

**Sample 00000021 Reference**:
```
"In the audio, there is a longer pause between \"Are you genuinely willing\" and \"to be with Xiaochuan?\" when the character expresses the phrase. She maintains direct eye contact with the other person and engages in a serious conversation. In the audio, there is a longer pause between \"Are you genuinely willing\" and \"to be with Xiaochuan?\" when the character expresses the phrase. This pause may indicate that the character has some doubts about the other person's true intentions or emotional feelings, or it could be due to uncertainty about the future or concerns about the relationship.In the text, the subtitle reads, \"Are you genuinely willing to be with Xiaochuan?\" Based on the video clues of the woman's calm facial expression, natural posture, absence of nervousness or unease, and her direct eye contact and serious conversation with the other person, it can be inferred that she is asking the question in a calm and sincere manner. However, based on the pause in the audio when the character expresses this sentence, it can be speculated that she may have some doubts or concerns about the other person's true intentions or emotional feelings. This pause may imply her uncertainty about the future or her worries about the relationship, so she may have a certain emotional state of questioning or concern when asking this question."
```

**é—®é¢˜**:
1. âŒ **å¥å­é‡å¤**: å¼€å¤´éƒ¨åˆ†é‡å¤äº†2æ¬¡
2. âŒ **åŒ…å«å­—å¹•**: "In the text, the subtitle reads, \"Are you genuinely willing to be with Xiaochuan?\""
3. âŒ **åŒ…å«è§†é¢‘ä¿¡æ¯**: "She maintains direct eye contact"ï¼ˆä¸æ˜¯audio-onlyï¼‰
4. âŒ **éå¸¸å†—é•¿**: 10è¡Œæ–‡æœ¬ï¼Œè´¨é‡å¾ˆå·®

---

## ğŸ” æ ¹æœ¬åŸå› åˆ†æ

### åŸå› 1: English Captionç¿»è¯‘è´¨é‡å·®

**æ•°æ®æ¥æº**: `data/processed/mer2024/manifest_audio_only_final.json`

**é—®é¢˜**: `english_caption`å­—æ®µæ˜¯æœºå™¨ç¿»è¯‘çš„ï¼Œè´¨é‡å¾ˆå·®ï¼š
- é‡å¤å¥å­
- åŒ…å«ä¸åº”è¯¥æœ‰çš„å†…å®¹ï¼ˆå­—å¹•ã€è§†é¢‘ä¿¡æ¯ï¼‰
- è¯­æ³•é”™è¯¯

**è¯æ®**ï¼ˆç¬¬8-9è¡Œï¼‰:
```json
"chinese_caption": "åœ¨éŸ³é¢‘ä¸­ï¼Œè§’è‰²åœ¨ä¸€å¼€å§‹æ—¶éŸ³è°ƒä¸ŠæŒ‘ï¼Œè¡¨è¾¾å‡ºä¸æ»¡ä¸ä¸è€ã€‚ä¹‹åè¾¹ç¬‘è¾¹è¯´ï¼Œè¡¨è¾¾å‡ºé«˜å…´ä¸­å¸¦ç€ä¸€ä»½è°ƒä¾ƒã€‚ï¼›è¿™å¥è¯å¯èƒ½æ˜¯ç”·æ€§åŒ»ç”Ÿå¯¹æŸä¸ªé—®é¢˜çš„å›ç­”æˆ–è€…è§£é‡Šã€‚æ ¹æ®éŸ³é¢‘çº¿ç´¢ä¸­è§’è‰²çš„è¯­è°ƒå˜åŒ–ï¼Œä»ä¸æ»¡ä¸ä¸è€åˆ°é«˜å…´ä¸­å¸¦ç€ä¸€ä»½è°ƒä¾ƒï¼Œæˆ‘ä»¬å¯ä»¥æ¨æ–­è¿™å¥è¯å¯èƒ½å¸¦æœ‰ä¸€ç§å¹½é»˜æˆ–è€…è‡ªå˜²çš„è¯­æ°”ã€‚ç”·æ€§åŒ»ç”Ÿé€šè¿‡å¼€ç©ç¬‘å’Œè°ƒä¾ƒçš„æ–¹å¼ç¼“è§£äº†ç´§å¼ çš„è¯é¢˜ï¼Œè¡¨ç°å‡ºä¸€ç§è½»æ¾å’Œæ„‰å¿«çš„æƒ…ç»ªã€‚",

"english_caption": "In the audio, the character's tone is initially raised... I, I, I don't have any experience in this area.\" ..."
```

**å¯¹æ¯”**:
- âœ… ä¸­æ–‡captionï¼šæµç•…ã€å®Œæ•´ã€åªæè¿°éŸ³é¢‘
- âŒ è‹±æ–‡captionï¼šé‡å¤ã€åŒ…å«å­—å¹•ã€è¯­æ³•é”™è¯¯

---

### åŸå› 2: è‹±è¯­Promptä¸å¤Ÿä¸¥æ ¼

**å½“å‰Prompt**ï¼ˆæ‚¨ä¿®æ”¹åçš„ï¼‰:
```
"As an expert in the field of emotions, please focus on the acoustic information in the audio to discern clues related to the emotions of the individual. Please provide a detailed description and ultimately predict the emotional state of the individual."
```

**é—®é¢˜**:
- âŒ æ²¡æœ‰æ˜ç¡®ç¦æ­¢å¯¹è¯å¼å†…å®¹
- âŒ æ²¡æœ‰æ˜ç¡®è¦æ±‚å®¢è§‚æè¿°
- âŒ æ²¡æœ‰é™åˆ¶å¥å­æ•°é‡

**å¯¹æ¯”ä¸­æ–‡Prompt**ï¼ˆæ›´ä¸¥æ ¼ï¼‰:
```
"ä»»åŠ¡ï¼šè¯·ç”Ÿæˆ"æƒ…æ„Ÿè¯´æ˜é•¿å¥"ï¼ŒæŒ‰ä»¥ä¸‹é¡ºåºç»„ç»‡å†…å®¹å¹¶ä¿æŒè‡ªç„¶æµç•…ï¼š
(1) å…ˆç”¨2â€“3ä¸ª"ç±»åˆ«çº§"çš„å£°å­¦/éŸµå¾‹çº¿ç´¢æè¿°è¯´è¯æ–¹å¼...
(2) æ®æ­¤ç»™å‡ºæœ€å¯èƒ½çš„å•ä¸€æƒ…ç»ª...
(3) è‹¥è¯­ä¹‰å†…å®¹æš—ç¤ºç¼˜ç”±ï¼Œå¯ç”¨æç®€çš„ä¸€å°çŸ­è¯­ç‚¹åˆ°ä¸ºæ­¢...

è¾“å‡ºè¦æ±‚ï¼š
- åªè¾“å‡º"ä¸¤åˆ°ä¸‰å¥ä¸­æ–‡é•¿å¥"ï¼Œçº¦70â€“100ä¸ªå­—ï¼›
- ä½¿ç”¨ç¬¬ä¸‰äººç§°æˆ–"è¯´è¯äºº"ç­‰æŒ‡ä»£ï¼›ä¸è¦å‡ºç°ç¬¬ä¸€/ç¬¬äºŒäººç§°ï¼›ä¸è¦è®¾é—®æˆ–é‚€è¯·å¯¹è¯ï¼›
- ä¸è¦ç¼–é€ å…·ä½“äººç‰©/æ—¶é—´/åœ°ç‚¹ç­‰ç»†èŠ‚ï¼›ä¸è¦å‡ºç°è¡¨æƒ…ç¬¦å·ã€è‹±æ–‡ã€Markdown/ä»£ç ã€‚"
```

**å…³é”®å·®å¼‚**:
- âœ… ä¸­æ–‡ï¼šæ˜ç¡®è¦æ±‚"ä¸è¦è®¾é—®æˆ–é‚€è¯·å¯¹è¯"
- âŒ è‹±æ–‡ï¼šæ²¡æœ‰è¿™ä¸ªè¦æ±‚

---

## ğŸ“Š é—®é¢˜å½±å“

### æŒ‡æ ‡å¼‚å¸¸

| æŒ‡æ ‡ | å€¼ | æ­£å¸¸èŒƒå›´ | çŠ¶æ€ |
|------|-----|---------|------|
| **corpus_bleu_en** | 0.0004 | 0.15-0.30 | âŒ æä½ |
| **avg_bleu_sentence** | 0.0237 | 0.15-0.30 | âŒ å¾ˆä½ |
| **avg_cider** | 0.9580 | 0.3-0.6 | âš ï¸ å¼‚å¸¸é«˜ |
| **avg_bertscore_f1** | 0.1481 | 0.85-0.95 | âŒ æä½ |
| **bertscore_precision** | 0.2939 | 0.85-0.95 | âŒ æä½ |
| **bertscore_recall** | 0.0079 | 0.85-0.95 | âŒ **æåº¦å¼‚å¸¸ä½** |

**å¼‚å¸¸åˆ†æ**:
1. **BLEUæ¥è¿‘0**: Referenceè´¨é‡å¤ªå·®ï¼Œå‡ ä¹æ— æ³•åŒ¹é…
2. **CIDErå¼‚å¸¸é«˜**: å¯èƒ½æ˜¯å› ä¸ºreferenceå¤ªé•¿ï¼ŒæŸäº›n-gramç¢°å·§åŒ¹é…
3. **BERTScoreæä½**: ç‰¹åˆ«æ˜¯Recallåªæœ‰0.0079ï¼ˆæ­£å¸¸åº”è¯¥>0.85ï¼‰
4. **BERTScore Recallè´Ÿå€¼**: Sample 00000021çš„recallæ˜¯**-0.079**ï¼ˆä¸æ­£å¸¸ï¼‰

---

## ğŸ’¡ é—®é¢˜æ ¹æº

### Reference Captioné—®é¢˜é“¾

```
1. MER2024åŸå§‹æ•°æ®é›†æ˜¯ä¸­æ–‡
   â†“
2. æœ‰äººç”¨æœºå™¨ç¿»è¯‘ç”Ÿæˆäº†english_caption
   â†“
3. ç¿»è¯‘è´¨é‡å¾ˆå·®ï¼š
   - é‡å¤å¥å­
   - åŒ…å«ä¸åº”è¯¥æœ‰çš„å†…å®¹ï¼ˆå­—å¹•ã€è§†é¢‘ï¼‰
   - è¯­æ³•é”™è¯¯
   â†“
4. ä½¿ç”¨è¿™äº›referenceè¯„ä¼°
   â†“
5. ç»“æœï¼šBLEU/BERTScoreæä½ï¼ˆä½†ä¸æ˜¯æ¨¡å‹çš„é”™ï¼‰
```

### ç”Ÿæˆè´¨é‡é—®é¢˜é“¾

```
1. è‹±è¯­Promptä¸å¤Ÿä¸¥æ ¼
   â†“
2. æ¨¡å‹ç”Ÿæˆå¯¹è¯å¼å†…å®¹ï¼ˆ"What do you think..."ï¼‰
   â†“
3. ä¸ç¬¦åˆä»»åŠ¡è¦æ±‚ï¼ˆåº”è¯¥æ˜¯å®¢è§‚æè¿°ï¼‰
   â†“
4. ä¸ä¸­æ–‡baselineä¸ä¸€è‡´ï¼ˆä¸­æ–‡ç¦æ­¢å¯¹è¯å¼ï¼‰
```

---

## ğŸ”§ è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆA: ä¿®å¤English Promptï¼ˆæ¨èï¼‰

#### å½“å‰Prompt
```
"As an expert in the field of emotions, please focus on the acoustic information in the audio to discern clues related to the emotions of the individual. Please provide a detailed description and ultimately predict the emotional state of the individual."
```

#### å»ºè®®Promptï¼ˆå¯¹é½ä¸­æ–‡ç‰ˆæœ¬ï¼‰
```
"Task: Generate a detailed emotional description based solely on acoustic features from the audio.

Structure your response as follows:
(1) First, describe 2-3 acoustic/prosodic features (choose from: speech rate, pitch variation, volume, pauses, tone quality, etc.) at a categorical level without specific values.
(2) Based on these features, identify the most likely single emotion.
(3) If the semantic content suggests a reason, briefly mention it in one short phrase (use "possibly/seems/might" to indicate uncertainty).

Requirements:
- Output 2-3 English sentences, approximately 50-70 words total.
- Use third-person references (e.g., "the speaker", "he/she"); do NOT use first/second person.
- Do NOT ask questions or invite conversation.
- Do NOT fabricate specific details about people, times, or places.
- Do NOT include emojis, Chinese text, Markdown, or code."
```

**å…³é”®æ”¹è¿›**:
- âœ… æ˜ç¡®è¦æ±‚"Do NOT ask questions or invite conversation"
- âœ… é™åˆ¶å¥å­æ•°é‡ï¼ˆ2-3å¥ï¼‰
- âœ… é™åˆ¶é•¿åº¦ï¼ˆ50-70è¯ï¼‰
- âœ… è¦æ±‚å®¢è§‚æè¿°ï¼ˆç¬¬ä¸‰äººç§°ï¼‰

---

### æ–¹æ¡ˆB: æ›´æ¢æ•°æ®é›†ï¼ˆæ¨èï¼‰

#### é—®é¢˜åˆ†æ
MER2024çš„`english_caption`è´¨é‡å¤ªå·®ï¼Œä¸é€‚åˆä½œä¸ºè‹±è¯­baselineçš„referenceã€‚

#### å»ºè®®
ä½¿ç”¨**SECAPæ•°æ®é›†**è¿›è¡Œè‹±è¯­æµ‹è¯•ï¼š

```bash
python experiments/runs/run_cloud_baseline.py \
    --dataset_type unified \
    --dataset_path data/processed/secap/manifest.json \
    --caption_type original \
    --language english \
    --prompt_type detailed \
    --max_samples 10 \
    --output_name cloud_secap_en
```

**åŸå› **:
- SECAPæ˜¯è‹±è¯­åŸç”Ÿæ•°æ®é›†
- Referenceè´¨é‡æ›´å¥½
- æ›´é€‚åˆè¯„ä¼°è‹±è¯­ç”Ÿæˆèƒ½åŠ›

---

### æ–¹æ¡ˆC: æ¸…ç†Reference Captionï¼ˆå¯é€‰ï¼‰

å¦‚æœå¿…é¡»ä½¿ç”¨MER2024è‹±è¯­captionï¼Œå¯ä»¥å°è¯•æ¸…ç†ï¼š

```python
def clean_english_caption(caption: str) -> str:
    """Clean machine-translated English caption"""
    # 1. ç§»é™¤é‡å¤å¥å­
    sentences = caption.split('. ')
    unique_sentences = []
    seen = set()
    for sent in sentences:
        sent_clean = sent.strip().lower()
        if sent_clean not in seen and sent_clean:
            unique_sentences.append(sent)
            seen.add(sent_clean)
    
    # 2. ç§»é™¤åŒ…å«å­—å¹•çš„å¥å­
    filtered = []
    for sent in unique_sentences:
        if 'subtitle' not in sent.lower() and 'text reads' not in sent.lower():
            filtered.append(sent)
    
    # 3. é‡æ–°ç»„åˆ
    return '. '.join(filtered[:3]) + '.'  # åªä¿ç•™å‰3å¥
```

**ç¼ºç‚¹**: å¯èƒ½ä»ç„¶è´¨é‡ä¸ä½³

---

## ğŸ“Š æŒ‡æ ‡å¼‚å¸¸åˆ†æ

### BERTScore Recall = 0.0079ï¼ˆæåº¦å¼‚å¸¸ï¼‰

**æ­£å¸¸BERTScore**:
| æŒ‡æ ‡ | æ­£å¸¸èŒƒå›´ | å®é™…å€¼ | çŠ¶æ€ |
|------|---------|--------|------|
| Precision | 0.85-0.95 | 0.2939 | âŒ å¾ˆä½ |
| Recall | 0.85-0.95 | **0.0079** | âŒ **æåº¦å¼‚å¸¸** |
| F1 | 0.85-0.95 | 0.1481 | âŒ å¾ˆä½ |

**ä¸ºä»€ä¹ˆRecallè¿™ä¹ˆä½ï¼Ÿ**

**BERTScore Recallå®šä¹‰**:
```
Recall = æœ‰å¤šå°‘referenceä¸­çš„è¯/æ¦‚å¿µè¢«generated textè¦†ç›–
```

**å½“å‰æƒ…å†µ**:
- Reference: è¶…é•¿ï¼ˆ300+è¯ï¼‰ï¼ŒåŒ…å«å¤§é‡ä¿¡æ¯ï¼ˆéŸ³é¢‘+å­—å¹•+è§†é¢‘ï¼‰
- Generated: æ­£å¸¸é•¿åº¦ï¼ˆ40-50è¯ï¼‰ï¼Œåªæœ‰éŸ³é¢‘ä¿¡æ¯
- Recall: ç”Ÿæˆæ–‡æœ¬åªè¦†ç›–äº†referenceçš„0.79%ï¼

**ç¤ºä¾‹**:
```
Reference (300è¯): 
  "tone raised... discussing serious issue... laughing... 
   I, I, I don't have experience... male doctor... 
   humorous tone... lightens topic..."

Generated (40è¯):
  "The voice is steady but carries uncertainty and hesitation..."

Recall: 40è¯ä¸­åŒ¹é…çš„ / 300è¯ â‰ˆ 0.0079 (0.79%)
```

---

### BLEU = 0.0004ï¼ˆå‡ ä¹ä¸º0ï¼‰

**æ­£å¸¸è‹±è¯­BLEU**: 0.15-0.30

**ä¸ºä»€ä¹ˆè¿™ä¹ˆä½ï¼Ÿ**

**BLEUå®šä¹‰**: åŸºäºn-gramåŒ¹é…ï¼ˆ1-gram, 2-gram, 3-gram, 4-gramï¼‰

**å½“å‰æƒ…å†µ**:
- Referenceè´¨é‡å·®ï¼ˆé‡å¤ã€é”™è¯¯ã€åŒ…å«å­—å¹•ï¼‰
- Generated textæ˜¯æ­£å¸¸è‹±è¯­ï¼Œä½†ä¸ä½è´¨é‡referenceæ— æ³•åŒ¹é…

**ç¤ºä¾‹**:
```
Reference: "In the audio, ... In the audio, ... I, I, I don't..."
Generated: "The voice is steady but carries uncertainty..."

n-gramåŒ¹é…: å‡ ä¹æ²¡æœ‰
BLEU: â‰ˆ 0.0004
```

---

### CIDEr = 0.9580ï¼ˆå¼‚å¸¸é«˜ï¼‰

**æ­£å¸¸CIDEr**: 0.3-0.6

**ä¸ºä»€ä¹ˆè¿™ä¹ˆé«˜ï¼Ÿ**

**å¯èƒ½åŸå› **:
1. Referenceå¤ªé•¿ï¼ˆ300+è¯ï¼‰ï¼ŒæŸäº›å¸¸è§è¯ç¢°å·§åŒ¹é…
2. CIDErçš„TF-IDFåŠ æƒå¯èƒ½è¢«è¶…é•¿referenceæ‰­æ›²
3. éœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥ï¼ˆå¯èƒ½æ˜¯è®¡ç®—é”™è¯¯ï¼‰

---

## ğŸ¯ æ ¸å¿ƒç»“è®º

### é—®é¢˜ä¼˜å…ˆçº§

| é—®é¢˜ | ä¸¥é‡æ€§ | å½±å“ | å»ºè®® |
|------|--------|------|------|
| **Referenceè´¨é‡å·®** | ğŸ”´ æä¸¥é‡ | è¯„ä¼°å®Œå…¨ä¸å¯é  | æ›´æ¢æ•°æ®é›†ï¼ˆSECAPï¼‰ |
| **å¯¹è¯å¼å†…å®¹** | ğŸ”´ ä¸¥é‡ | ä¸ä¸­æ–‡ä¸ä¸€è‡´ | ä¿®å¤Prompt |
| **BLEUæä½** | ğŸŸ¡ ä¸­ç­‰ | æŒ‡æ ‡ä¸å¯ä¿¡ | ç»“æœï¼šæ›´æ¢æ•°æ®é›† |
| **BERTScoreæä½** | ğŸŸ¡ ä¸­ç­‰ | æŒ‡æ ‡ä¸å¯ä¿¡ | ç»“æœï¼šæ›´æ¢æ•°æ®é›† |

---

## ğŸ’¡ æ¨èè¡ŒåŠ¨æ–¹æ¡ˆ

### Step 1: ä¿®å¤è‹±è¯­Promptï¼ˆç«‹å³ï¼‰

æ·»åŠ æ˜ç¡®çš„çº¦æŸï¼Œç¦æ­¢å¯¹è¯å¼å†…å®¹ã€‚

**ä¿®æ”¹ä½ç½®**: `experiments/runs/run_cloud_baseline.py` (å’Œå…¶ä»–baselineè„šæœ¬)

```python
elif language == "english":
    return """Task: Generate a detailed emotional description based solely on acoustic features from the audio.

Structure your response as follows:
(1) First, describe 2-3 acoustic/prosodic features (choose from: speech rate, pitch variation, volume, pauses, tone quality, etc.) at a categorical level without specific values.
(2) Based on these features, identify the most likely single emotion.
(3) If the semantic content suggests a reason, briefly mention it in one short phrase (use "possibly/seems/might" to indicate uncertainty).

Requirements:
- Output 2-3 English sentences, approximately 50-70 words total.
- Use third-person references (e.g., "the speaker", "he/she"); do NOT use first/second person.
- Do NOT ask questions or invite conversation.
- Do NOT fabricate specific details about people, times, or places.
- Do NOT include emojis, Chinese text, Markdown, or code."""
```

---

### Step 2: æ›´æ¢æ•°æ®é›†ï¼ˆå¼ºçƒˆæ¨èï¼‰

**ä»MER2024åˆ‡æ¢åˆ°SECAP**:

```bash
# ä½¿ç”¨SECAPï¼ˆè‹±è¯­åŸç”Ÿæ•°æ®é›†ï¼‰
python experiments/runs/run_cloud_baseline.py \
    --dataset_type unified \
    --dataset_path data/processed/secap/manifest.json \
    --caption_type original \
    --language english \
    --prompt_type detailed \
    --max_samples 10 \
    --output_name cloud_secap_en
```

**ä¼˜åŠ¿**:
- âœ… SECAPæ˜¯è‹±è¯­åŸç”Ÿæ•°æ®é›†
- âœ… Referenceè´¨é‡é«˜
- âœ… æ²¡æœ‰ç¿»è¯‘é—®é¢˜
- âœ… æŒ‡æ ‡æ‰æœ‰æ„ä¹‰

---

### Step 3: æˆ–è€…ä½¿ç”¨ä¸­æ–‡æ•°æ®é›†ï¼ˆå¤‡é€‰ï¼‰

å¦‚æœæƒ³ç»§ç»­ç”¨MER2024ï¼Œåº”è¯¥ç”¨**ä¸­æ–‡**:

```bash
python experiments/runs/run_cloud_baseline.py \
    --dataset_type unified \
    --dataset_path data/processed/mer2024/manifest_audio_only_final.json \
    --caption_type audio_only \
    --language chinese \
    --prompt_type detailed \
    --max_samples 10 \
    --output_name cloud_mer2024_zh
```

---

## ğŸ” è¿›ä¸€æ­¥éªŒè¯

### æ£€æŸ¥SECAPæ•°æ®é›†è´¨é‡

è®©æˆ‘æŸ¥çœ‹SECAPçš„æ ·æœ¬ï¼š

```bash
# æŸ¥çœ‹SECAPçš„ç¬¬ä¸€ä¸ªæ ·æœ¬
head -50 data/processed/secap/manifest.json
```

å¦‚æœSECAPçš„captionè´¨é‡å¥½ï¼Œé‚£å°±åº”è¯¥ç”¨SECAPè¿›è¡Œè‹±è¯­æµ‹è¯•ã€‚

---

## ğŸ“ æ€»ç»“

### æ ¸å¿ƒé—®é¢˜

1. âŒ **MER2024çš„english_captionè´¨é‡æå·®**ï¼ˆæœºå™¨ç¿»è¯‘ã€é‡å¤ã€åŒ…å«å­—å¹•ï¼‰
2. âŒ **ç”Ÿæˆäº†å¯¹è¯å¼å†…å®¹**ï¼ˆPromptä¸å¤Ÿä¸¥æ ¼ï¼‰
3. âŒ **æ‰€æœ‰æŒ‡æ ‡éƒ½ä¸å¯ä¿¡**ï¼ˆBLEU=0.0004, BERTScore Recall=0.0079ï¼‰

### æ¨èæ–¹æ¡ˆ

**ç«‹å³æ‰§è¡Œ**:
1. âœ… ä¿®å¤è‹±è¯­Promptï¼ˆç¦æ­¢å¯¹è¯å¼ï¼‰
2. âœ… åˆ‡æ¢åˆ°SECAPæ•°æ®é›†ï¼ˆè‹±è¯­åŸç”Ÿï¼‰

**éªŒè¯**:
- æ£€æŸ¥ç”Ÿæˆæ–‡æœ¬æ— å¯¹è¯å¼å†…å®¹
- BLEUåº”è¯¥åœ¨0.15-0.30èŒƒå›´
- BERTScoreåº”è¯¥åœ¨0.85-0.95èŒƒå›´

**æš‚æ—¶ä¸è¦ç”¨MER2024çš„è‹±è¯­caption**:
- è´¨é‡å¤ªå·®ï¼Œæ— æ³•ä½œä¸ºå¯é çš„reference
- è¯„ä¼°ç»“æœæ²¡æœ‰æ„ä¹‰

---

**éœ€è¦æˆ‘å¸®æ‚¨ä¿®å¤è‹±è¯­Promptå¹¶åˆ‡æ¢åˆ°SECAPå—ï¼Ÿ** ğŸš€

