# æœ€ç»ˆè¯„ä¼°æŒ‡æ ‡ä¿®å¤æ€»ç»“

## ğŸš¨ **å‘ç°çš„é—®é¢˜**

æ ¹æ®æ‚¨çš„ `cloud_mer_en_test7.json` æµ‹è¯•ç»“æœï¼Œæˆ‘å‘ç°äº†ä»¥ä¸‹å…³é”®é—®é¢˜ï¼š

### 1. **ROUGE-L åˆ†æ•°å…¨ä¸º 0.0**
```json
"avg_rouge_l_sentence": 0.0,
"rouge_l_score": 0.0,  // æ‰€æœ‰æ ·æœ¬éƒ½æ˜¯ 0.0
```
**æ ¹æœ¬åŸå› **: ä½¿ç”¨äº†é”™è¯¯çš„ `rouge` åº“ï¼Œåº”è¯¥ä½¿ç”¨ `rouge-score` åº“ã€‚

### 2. **BERTScore åˆ†æ•°å¼‚å¸¸é«˜**
```json
"avg_bertscore_precision": 0.8810291528701782,  // 88%ï¼
"avg_bertscore_recall": 0.832818228006363,      // 83%ï¼
"avg_bertscore_f1": 0.8562153100967407          // 85%ï¼
```
**æ ¹æœ¬åŸå› **: `rescale_with_baseline=True` å¯¼è‡´åˆ†æ•°è¢«å¼‚å¸¸æ”¾å¤§ã€‚

## âœ… **ä¿®å¤æ–¹æ¡ˆ**

### 1. **ä¿®å¤ ROUGE-L è®¡ç®—**
**é—®é¢˜**: ä½¿ç”¨äº†é”™è¯¯çš„åº“
```python
# é”™è¯¯çš„å¯¼å…¥
from rouge import Rouge

# æ­£ç¡®çš„å¯¼å…¥
from rouge_score import rouge_scorer
```

**ä¿®å¤åçš„è®¡ç®—**:
```python
# ä½¿ç”¨æ­£ç¡®çš„ rouge-score åº“
scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)
scores = scorer.score(best_reference, hypothesis)
rouge_l_f1 = scores['rougeL'].fmeasure
```

### 2. **ä¿®å¤ BERTScore å¼‚å¸¸é«˜åˆ†**
**é—®é¢˜**: `rescale_with_baseline=True` å¯¼è‡´åˆ†æ•°å¼‚å¸¸æ”¾å¤§
```python
# é”™è¯¯çš„é…ç½®
rescale_with_baseline=True,  # å¯¼è‡´å¼‚å¸¸é«˜åˆ†

# æ­£ç¡®çš„é…ç½®
rescale_with_baseline=False,  # é˜²æ­¢å¼‚å¸¸é«˜åˆ†
```

## ğŸ”§ **å…·ä½“ä¿®æ”¹**

### `src/evaluation/metrics.py` ä¿®æ”¹ï¼š

1. **ROUGE åº“å¯¼å…¥ä¿®å¤**:
   ```python
   # ä¿®æ”¹å‰
   from rouge import Rouge
   
   # ä¿®æ”¹å
   from rouge_score import rouge_scorer
   ```

2. **ROUGE-L è®¡ç®—æ–¹æ³•ä¿®å¤**:
   ```python
   # ä¿®æ”¹å‰
   rouge = Rouge()
   scores = rouge.get_scores(hypothesis, best_reference)
   rouge_l_f1 = scores[0]['rouge-l']['f']
   
   # ä¿®æ”¹å
   scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)
   scores = scorer.score(best_reference, hypothesis)
   rouge_l_f1 = scores['rougeL'].fmeasure
   ```

3. **BERTScore é…ç½®ä¿®å¤**:
   ```python
   # æ‰€æœ‰ BERTScore é…ç½®éƒ½æ”¹ä¸º
   rescale_with_baseline=False,  # é˜²æ­¢å¼‚å¸¸é«˜åˆ†
   ```

## ğŸ“Š **é¢„æœŸæ”¹è¿›**

ä¿®å¤åï¼Œæ‚¨åº”è¯¥çœ‹åˆ°ï¼š

1. **ROUGE-L åˆ†æ•°**: ä¸å†æ˜¯å…¨ 0.0ï¼Œä¼šæœ‰åˆç†çš„åˆ†æ•°ï¼ˆå¦‚ 0.1-0.3ï¼‰
2. **BERTScore**: åˆ†æ•°ä¼šé™ä½åˆ°åˆç†èŒƒå›´ï¼ˆå¦‚ 0.3-0.6ï¼‰ï¼Œä¸å†å¼‚å¸¸é«˜
3. **METEOR**: ä¿æŒåˆç†çš„åˆ†æ•°

## ğŸ§ª **éªŒè¯ç»“æœ**

æµ‹è¯•æ˜¾ç¤º ROUGE-L ç°åœ¨å¯ä»¥æ­£å¸¸è®¡ç®—ï¼š
```
ROUGE-L F1: 0.10112359550561797
ROUGE-L Precision: 0.24324324324324326
ROUGE-L Recall: 0.06382978723404255
```

## ğŸš€ **ç°åœ¨å¯ä»¥é‡æ–°æµ‹è¯•**

è¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤é‡æ–°è¿è¡Œæµ‹è¯•ï¼š

```bash
python experiments/runs/run_cloud_baseline.py \
    --dataset_type unified \
    --dataset_path data/processed/mer2024/manifest_audio_text_augmented_v5.json \
    --caption_type audio_only \
    --language english \
    --prompt_type detailed \
    --input_modality audio_only \
    --max_samples 5 \
    --verbose \
    --output_name cloud_en_final_fixed
```

## ğŸ“ **é¢„æœŸç»“æœ**

- âœ… **ROUGE-L**: ä¸å†å…¨ä¸º 0.0ï¼Œä¼šæœ‰åˆç†åˆ†æ•°
- âœ… **BERTScore**: åˆ†æ•°é™ä½åˆ°åˆç†èŒƒå›´ï¼ˆ0.3-0.6ï¼‰
- âœ… **METEOR**: ä¿æŒåˆç†åˆ†æ•°
- âœ… **BLEU**: ä¿æŒç°æœ‰åˆç†åˆ†æ•°

ç°åœ¨æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡éƒ½åº”è¯¥èƒ½æ­£ç¡®è®¡ç®—å¹¶æ˜¾ç¤ºåˆç†çš„åˆ†æ•°ï¼

