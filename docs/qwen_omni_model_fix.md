# Qwen2.5-Omni Model Loading Fix

## âš ï¸ é”™è¯¯ä¿¡æ¯

```
You are using a model of type qwen2_5_omni to instantiate a model of type qwen2_audio. 
This is not supported for all configurations of models and can yield errors.
```

---

## ğŸ” é—®é¢˜åˆ†æ

### åŸä»£ç ï¼ˆé”™è¯¯ï¼‰

```python
from transformers import Qwen2AudioForConditionalGeneration, AutoProcessor

model = Qwen2AudioForConditionalGeneration.from_pretrained(
    model_name,
    torch_dtype=torch.float16 if 'cuda' in device else torch.float32,
    device_map=device if 'cuda' in device else None
)
```

**é—®é¢˜**:
- âŒ ä½¿ç”¨äº† **`Qwen2AudioForConditionalGeneration`** (æ—§ç‰ˆæœ¬çš„ç±»)
- âŒ Qwen2.5-Omni æ¨¡å‹åº”è¯¥ä½¿ç”¨ä¸“é—¨çš„ **`Qwen2_5OmniForConditionalGeneration`** ç±»
- âŒ ç±»å‹ä¸åŒ¹é…å¯¼è‡´è­¦å‘Šå’Œæ½œåœ¨é”™è¯¯

---

## âœ… å®˜æ–¹æ­£ç¡®ç”¨æ³•

### æ¥æºï¼š`Qwen2.5-Omni-README.md` Line 744-760

```python
from transformers import Qwen2_5OmniForConditionalGeneration, Qwen2_5OmniProcessor

# default: Load the model on the available device(s)
model = Qwen2_5OmniForConditionalGeneration.from_pretrained(
    "Qwen/Qwen2.5-Omni-7B", 
    torch_dtype="auto",      # â† ä½¿ç”¨ "auto" è€Œä¸æ˜¯æ‰‹åŠ¨æŒ‡å®š
    device_map="auto"        # â† ä½¿ç”¨ "auto" è‡ªåŠ¨åˆ†é…
)

processor = Qwen2_5OmniProcessor.from_pretrained("Qwen/Qwen2.5-Omni-7B")
```

---

## ğŸ”§ ä¿®å¤æ–¹æ¡ˆ

### ä¿®æ”¹1: å¯¼å…¥æ­£ç¡®çš„ç±» (Line 26)

```python
# é”™è¯¯ âŒ
from transformers import Qwen2AudioForConditionalGeneration, AutoProcessor

# æ­£ç¡® âœ…
from transformers import Qwen2_5OmniForConditionalGeneration, Qwen2_5OmniProcessor
```

---

### ä¿®æ”¹2: ä½¿ç”¨å®˜æ–¹æ¨èçš„åŠ è½½æ–¹å¼ (Line 46-75)

```python
def load_qwen_model(model_name: str, device: str):
    """
    Load Qwen-2.5-Omni model and processor (text-only mode)
    """
    logger.info(f"Loading model: {model_name}")
    
    # Load processor
    processor = Qwen2_5OmniProcessor.from_pretrained(model_name)
    
    # Load model (use torch_dtype="auto" as recommended by official docs)
    model = Qwen2_5OmniForConditionalGeneration.from_pretrained(
        model_name,
        torch_dtype="auto",    # âœ… å®˜æ–¹æ¨èä½¿ç”¨ "auto"
        device_map="auto"       # âœ… è‡ªåŠ¨åˆ†é…è®¾å¤‡
    )
    
    # Disable audio output to save memory (we only need text output)
    model.disable_talker()      # âœ… èŠ‚çœçº¦2GBæ˜¾å­˜
    
    model.eval()
    
    logger.info(f"Model loaded successfully on {device}")
    return model, processor
```

---

### ä¿®æ”¹3: æ·»åŠ  `return_audio=False` (Line 137-148)

```python
# Generate (text-only, no audio output)
with torch.no_grad():
    output_ids = model.generate(
        **inputs,
        max_new_tokens=max_new_tokens,
        temperature=temperature,
        do_sample=True if temperature > 0 else False,
        top_p=0.9,
        pad_token_id=processor.tokenizer.pad_token_id,
        eos_token_id=processor.tokenizer.eos_token_id,
        return_audio=False  # âœ… åªè¿”å›æ–‡æœ¬è¾“å‡º
    )
```

---

## ğŸ“š å®˜æ–¹æ–‡æ¡£å‚è€ƒ

### 1. Text-only Generation Mode

**æ¥æº**: `Qwen2.5-Omni-README.md` Line 1001-1023

```python
# Method 1: Disable talker after loading
model = Qwen2_5OmniForConditionalGeneration.from_pretrained(
    "Qwen/Qwen2.5-Omni-7B",
    torch_dtype="auto",
    device_map="auto"
)
model.disable_talker()  # Save about 2GB of GPU memory

# Method 2: Set return_audio=False during generation
text_ids = model.generate(**inputs, return_audio=False)
```

**è¯´æ˜**:
- `model.disable_talker()`: ç¦ç”¨éŸ³é¢‘ç”Ÿæˆæ¨¡å—ï¼ŒèŠ‚çœçº¦2GBæ˜¾å­˜
- `return_audio=False`: ç”Ÿæˆæ—¶åªè¿”å›æ–‡æœ¬ï¼Œä¸ç”ŸæˆéŸ³é¢‘

---

### 2. æ¨èçš„åŠ è½½æ–¹å¼

**æ¥æº**: `Qwen2.5-Omni-README.md` Line 744-760

```python
# Recommended: Use torch_dtype="auto" and device_map="auto"
model = Qwen2_5OmniForConditionalGeneration.from_pretrained(
    "Qwen/Qwen2.5-Omni-7B", 
    torch_dtype="auto",      # Auto-select dtype based on device
    device_map="auto"        # Auto-distribute layers across devices
)
```

**ä¼˜åŠ¿**:
- âœ… è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ•°æ®ç±»å‹ï¼ˆFP16/BF16/FP32ï¼‰
- âœ… è‡ªåŠ¨åˆ†é…æ¨¡å‹å±‚åˆ°å¯ç”¨è®¾å¤‡
- âœ… æ›´å¥½çš„å†…å­˜ç®¡ç†

---

### 3. FlashAttention-2 åŠ é€Ÿï¼ˆå¯é€‰ï¼‰

**æ¥æº**: `Qwen2.5-Omni-README.md` Line 1043-1064

```python
# For better performance, enable FlashAttention-2
model = Qwen2_5OmniForConditionalGeneration.from_pretrained(
    "Qwen/Qwen2.5-Omni-7B",
    device_map="auto",
    torch_dtype=torch.bfloat16,
    attn_implementation="flash_attention_2",  # Enable Flash Attention
)
```

**éœ€è¦å…ˆå®‰è£…**:
```bash
pip install -U flash-attn --no-build-isolation
```

---

## ğŸ¯ ä¿®æ”¹å‰åå¯¹æ¯”

### Before (é”™è¯¯)

| é¡¹ç›® | åŸç‰ˆæœ¬ | é—®é¢˜ |
|------|--------|------|
| Import | `Qwen2AudioForConditionalGeneration` | âŒ ç±»å‹ä¸åŒ¹é… |
| Processor | `AutoProcessor` | âŒ ä¸æ˜¯ä¸“ç”¨å¤„ç†å™¨ |
| torch_dtype | `torch.float16` | âš ï¸ æ‰‹åŠ¨æŒ‡å®š |
| device_map | `device if 'cuda' in device else None` | âš ï¸ æ‰‹åŠ¨ç®¡ç† |
| Talker | æœªç¦ç”¨ | âš ï¸ æµªè´¹2GBæ˜¾å­˜ |
| return_audio | æœªè®¾ç½® | âš ï¸ å¯èƒ½è¿”å›éŸ³é¢‘ |

### After (æ­£ç¡®)

| é¡¹ç›® | ä¿®å¤ç‰ˆæœ¬ | ä¼˜åŠ¿ |
|------|---------|------|
| Import | `Qwen2_5OmniForConditionalGeneration` | âœ… æ­£ç¡®ç±»å‹ |
| Processor | `Qwen2_5OmniProcessor` | âœ… ä¸“ç”¨å¤„ç†å™¨ |
| torch_dtype | `"auto"` | âœ… è‡ªåŠ¨ä¼˜åŒ– |
| device_map | `"auto"` | âœ… è‡ªåŠ¨åˆ†é… |
| Talker | `model.disable_talker()` | âœ… èŠ‚çœ2GB |
| return_audio | `False` | âœ… æ˜ç¡®åªè¦æ–‡æœ¬ |

---

## ğŸš€ é¢„æœŸæ•ˆæœ

### Before (åŸç‰ˆæœ¬)

```
WARNING: You are using a model of type qwen2_5_omni to instantiate 
a model of type qwen2_audio. This is not supported...
```

### After (ä¿®å¤å)

```
INFO: Loading model: Qwen/Qwen2.5-Omni-7B
INFO: Model loaded successfully on cuda:0
```

**æ— è­¦å‘Šï¼Œæ­£å¸¸åŠ è½½** âœ…

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–æ€»ç»“

| ä¼˜åŒ–é¡¹ | æ•ˆæœ | è¯´æ˜ |
|--------|------|------|
| ä½¿ç”¨æ­£ç¡®çš„ç±» | æ¶ˆé™¤è­¦å‘Š | é¿å…ç±»å‹ä¸åŒ¹é… |
| `torch_dtype="auto"` | è‡ªåŠ¨ä¼˜åŒ– | æ ¹æ®è®¾å¤‡é€‰æ‹©æœ€ä½³ç±»å‹ |
| `device_map="auto"` | è‡ªåŠ¨åˆ†é… | å¤šGPUè‡ªåŠ¨å¹³è¡¡ |
| `disable_talker()` | èŠ‚çœ2GBæ˜¾å­˜ | åªéœ€æ–‡æœ¬è¾“å‡º |
| `return_audio=False` | åŠ å¿«ç”Ÿæˆ | è·³è¿‡éŸ³é¢‘ç”Ÿæˆ |

---

## âœ… æµ‹è¯•å‘½ä»¤

```bash
cd /data/gpfs/projects/punim2341/jiajunlu/edgecloud-sec

python tools/extract_emotion_labels.py \
    --input_json experiments/results/cloud_mer_en_test1.json \
    --output_csv MERTools/MER2024/ov_store/predict-openset-qwen-fixed.csv \
    --model_name Qwen/Qwen2.5-Omni-7B \
    --device cuda:0
```

**é¢„æœŸ**: 
- âœ… æ— è­¦å‘Šä¿¡æ¯
- âœ… æ­£å¸¸åŠ è½½æ¨¡å‹
- âœ… æˆåŠŸç”Ÿæˆæ ‡ç­¾

---

## ğŸ“ æ€»ç»“

### æ ¸å¿ƒä¿®æ”¹

1. âœ… **Import**: `Qwen2_5OmniForConditionalGeneration` + `Qwen2_5OmniProcessor`
2. âœ… **Loading**: `torch_dtype="auto"` + `device_map="auto"`
3. âœ… **Optimization**: `model.disable_talker()` + `return_audio=False`

### å‚è€ƒæ–‡æ¡£

- `Qwen2.5-Omni-README.md` Line 744-760 (æ¨èåŠ è½½æ–¹å¼)
- `Qwen2.5-Omni-README.md` Line 1001-1023 (Text-only mode)
- `qwen2_5_omni.md` Line 106-158 (Text-only generation)

**æ‰€æœ‰ä¿®æ”¹éƒ½åŸºäºå®˜æ–¹æ–‡æ¡£æ¨èï¼** ğŸ“šâœ…

