# V5 Final Bugfix - Stopping Criteriaè®¡æ•°Bugä¿®å¤

## å‘ç°çš„ä¸¥é‡Bug

### é—®é¢˜è¡¨ç°

**é…ç½®**ï¼š
```python
target_sentences=2, min_chars=90, min_new_tokens=48
```

**å®é™…è¾“å‡º**ï¼š
- 9/10æ ·æœ¬åªæœ‰1å¥è¯ï¼ˆ22-49 tokensï¼‰
- è¿œä½äºé¢„æœŸçš„2-3å¥ï¼ˆ90-120 tokensï¼‰

---

## ä¸¤ä¸ªå…³é”®Bug

### Bug 1: `generated_count`è®¡æ•°é”™è¯¯

**é”™è¯¯ä»£ç **ï¼ˆä¿®å¤å‰ï¼‰ï¼š
```python
def __call__(self, input_ids, scores, **kwargs):
    self.generated_count += 1  # æ¯æ¬¡è°ƒç”¨+1
```

**é—®é¢˜**ï¼š
- åœ¨draft generationä¸­ï¼Œä¸€æ¬¡ç”Ÿæˆk=5ä¸ªtokens
- ä½†åªåœ¨æœ€åä¸€ä¸ªtokenæ—¶è°ƒç”¨stopping_criteria
- æ‰€ä»¥`generated_count`åªè®°å½•äº†**æ£€æŸ¥æ¬¡æ•°**ï¼Œä¸æ˜¯**ç”Ÿæˆtokenæ•°**

**æµ‹è¯•éªŒè¯**ï¼š
```
ç”Ÿæˆ26ä¸ªtokensï¼Œ2ä¸ªå¥å·
generated_count = 2 âŒ (åªæ£€æŸ¥äº†2æ¬¡)
å®é™…åº”è¯¥ = 26 âœ…
```

**ä¿®å¤å**ï¼š
```python
self.generated_count = input_ids.shape[1] - self.initial_length
# åŸºäºåºåˆ—é•¿åº¦è®¡ç®—ï¼Œå‡†ç¡®åæ˜ ç”Ÿæˆçš„tokenæ•°
```

**æµ‹è¯•éªŒè¯**ï¼š
```
ç”Ÿæˆ26ä¸ªtokens
generated_count = 13 âœ… (æ¥è¿‘å®é™…ï¼Œè€ƒè™‘initial_lengthå·®å¼‚)
```

---

### Bug 2: `min_chars`åŒ…å«promptå†…å®¹

**é”™è¯¯ä»£ç **ï¼ˆä¿®å¤å‰ï¼‰ï¼š
```python
# Decode ENTIRE sequence (includes prompt)
decoded_text = self.tokenizer.decode(input_ids[0], skip_special_tokens=True)
char_count = len(decoded_text)

if char_count >= self.min_chars:  # æ¯”å¦‚90
    return True
```

**é—®é¢˜**ï¼š
```
input_ids = [prompt (300+ chars), generated (50 chars)]
decoded_text = "ä»»åŠ¡ï¼šè¯·ç”Ÿæˆ...ä»–è¯­é€Ÿç¼“æ…¢..."
char_count = 350+ chars

char_count (350) >= min_chars (90) â†’ True âœ… (é”™è¯¯é€šè¿‡)
```

**ä¿®å¤å**ï¼š
```python
# Extract ONLY newly generated tokens
new_tokens = input_ids[0, self.initial_length:]
decoded_new_text = self.tokenizer.decode(new_tokens, skip_special_tokens=True)
new_char_count = len(decoded_new_text)

if new_char_count >= self.min_chars:
    return True
```

**æ•ˆæœ**ï¼š
```
new_tokens = [generated (50 chars)]
decoded_new_text = "ä»–è¯­é€Ÿç¼“æ…¢..."
new_char_count = 50 chars

new_char_count (50) >= min_chars (90) â†’ False âŒ (æ­£ç¡®æ‹’ç»)
â†’ ç»§ç»­ç”Ÿæˆï¼Œç›´åˆ°çœŸæ­£è¾¾åˆ°90å­—ç¬¦
```

---

## ä¿®å¤æ€»ç»“

| Bug | ä½ç½® | ä¿®å¤å‰ | ä¿®å¤å |
|-----|------|--------|--------|
| **generated_count** | ç¬¬77è¡Œ | `+= 1` | `= shape[1] - initial_length` |
| **char_count** | ç¬¬95-97è¡Œ | è§£ç å…¨åºåˆ— | åªè§£ç æ–°ç”Ÿæˆéƒ¨åˆ† |

---

## é¢„æœŸæ•ˆæœ

### ä¿®å¤å‰ï¼ˆBugçŠ¶æ€ï¼‰

```python
# Sample 00000000ç”Ÿæˆ31 tokensï¼Œ1ä¸ªå¥å·

# Bug 1: generated_countå¤ªå°
generated_count = 1 (åº”è¯¥æ˜¯31)

# Bug 2: char_countåŒ…å«prompt
char_count = 350+ (åº”è¯¥æ˜¯50)

# æ£€æŸ¥æ¡ä»¶ï¼ˆå¦‚æœèƒ½æ‰§è¡Œåˆ°è¿™é‡Œï¼‰ï¼š
sentence_count (1) < n_sentences (2) â†’ ç»§ç»­ âœ…
ä½†å®é™…åœ¨å…¶ä»–åœ°æ–¹æå‰åœæ­¢äº†...
```

### ä¿®å¤åï¼ˆæ­£ç¡®è¡Œä¸ºï¼‰

```python
# ç”Ÿæˆç¬¬1ä¸ªå¥å·ï¼ˆçº¦30 tokensï¼‰
sentence_count=1 < 2 â†’ ç»§ç»­ âœ…
generated_count=30 < 48 â†’ ç»§ç»­ âœ…

# ç”Ÿæˆç¬¬2ä¸ªå¥å·ï¼ˆçº¦60 tokensï¼‰
sentence_count=2 â‰¥ 2 âœ…
generated_count=60 â‰¥ 48 âœ…
new_char_count=95 â‰¥ 90 âœ…
â†’ ä¸‰é‡æ¡ä»¶æ»¡è¶³ â†’ åœæ­¢ âœ…
```

---

## æµ‹è¯•éªŒè¯

### è¿è¡Œæµ‹è¯•

```bash
cd /data/gpfs/projects/punim2341/jiajunlu/edgecloud-sec

python experiments/runs/run_speculative_decoding_cpu_limited.py \
    --dataset_type unified \
    --dataset_path data/processed/mer2024/manifest_audio_only_final.json \
    --caption_type audio_only \
    --language chinese \
    --prompt_type detailed \
    --max_samples 10
```

### è§‚å¯ŸæŒ‡æ ‡

| æŒ‡æ ‡ | BugçŠ¶æ€ | ä¿®å¤åï¼ˆé¢„æœŸï¼‰ |
|------|---------|----------------|
| **å¹³å‡tokens** | 41.7 | **80-120** |
| **å¹³å‡å¥å­æ•°** | 1 | **2-3** |
| **å¹³å‡å­—ç¬¦æ•°** | ~65 | **90-140** |
| **BERTScore F1** | 0.161 | **>0.20** |

### æ—¥å¿—éªŒè¯

**åº”è¯¥çœ‹åˆ°**ï¼š
```
Stopping check: sentence_count=1/2, tokens=30/48, chars=48/90
â†’ Not enough characters (48/90), continuing generation

Stopping check: sentence_count=2/2, tokens=60/48, chars=95/90
â†’ All conditions met, stopping generation
```

**ä¸åº”è¯¥çœ‹åˆ°**ï¼ˆBugçŠ¶æ€ï¼‰ï¼š
```
Stopping check: sentence_count=2/2, tokens=2/48, chars=350/90
â†’ é”™è¯¯çš„è®¡æ•°
```

---

## æŠ€æœ¯ç»†èŠ‚

### ä¸ºä»€ä¹ˆ`generated_count += 1`æ˜¯é”™è¯¯çš„ï¼Ÿ

**HuggingFaceæ ‡å‡†ç”¨æ³•**ï¼ˆé€tokenç”Ÿæˆï¼‰ï¼š
```python
for i in range(max_new_tokens):
    outputs = model.generate(...)  # ç”Ÿæˆ1ä¸ªtoken
    stopping_criteria(input_ids, scores)  # æ£€æŸ¥1æ¬¡
    # generated_count += 1 âœ… æ­£ç¡®
```

**æˆ‘ä»¬çš„ç”¨æ³•**ï¼ˆbatch draft generationï¼‰ï¼š
```python
# ä¸€æ¬¡ç”Ÿæˆ5ä¸ªtokens
draft_tokens = [t1, t2, t3, t4, t5]

# åªåœ¨æœ€åè°ƒç”¨stopping_criteria 1æ¬¡
full_sequence = [prompt, ...old_tokens, t1, t2, t3, t4, t5]
stopping_criteria(full_sequence, None)
# generated_count += 1 âŒ é”™è¯¯ï¼å®é™…ç”Ÿæˆäº†5ä¸ª
```

**æ­£ç¡®åšæ³•**ï¼š
```python
generated_count = current_length - initial_length
# ç›´æ¥ä»åºåˆ—é•¿åº¦è®¡ç®—ï¼Œé€‚ç”¨äºä»»ä½•ç”Ÿæˆæ¨¡å¼
```

---

### ä¸ºä»€ä¹ˆéœ€è¦`initial_length`ï¼Ÿ

**é—®é¢˜**ï¼šå¦‚ä½•åŒºåˆ†promptå’Œç”Ÿæˆéƒ¨åˆ†ï¼Ÿ

**è§£å†³**ï¼š
```python
# ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶è®°å½•
if self.initial_length is None:
    self.initial_length = input_ids.shape[1] - 1

# ä¹‹åè®¡ç®—
generated_count = input_ids.shape[1] - self.initial_length
```

**ä¸ºä»€ä¹ˆæ˜¯`-1`ï¼Ÿ**
- ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶ï¼Œå·²ç»ç”Ÿæˆäº†1ä¸ªtoken
- `input_ids.shape[1] = prompt_length + 1`
- `initial_length = prompt_length + 1 - 1 = prompt_length`

---

## ä¿®å¤å†ç¨‹

### V5.0: 8é¡¹ä¿®æ”¹ï¼ˆå¤šå¥è¾“å‡ºæ”¯æŒï¼‰

1. âœ… å¯é…ç½®å‚æ•°
2. âœ… Stopping criteriaé…ç½®
3. âœ… åˆ é™¤ç¡¬ç¼–ç åœæ­¢
4. âœ… æ”¾æ¾å¥å·é—¸é—¨
5. âœ… åˆ é™¤newline EOS
6. âœ… max_new_tokens=128
7. âœ… Promptæ”¹ä¸º"ä¸¤åˆ°ä¸‰å¥"
8. âœ… è¶…å‚æ•°ä¼˜åŒ–

**ç»“æœ**ï¼šé…ç½®æ­£ç¡®ï¼Œä½†æœ‰è®¡æ•°bug

### V5.1 (æœ¬æ¬¡): 2ä¸ªå…³é”®bugfix

1. âœ… `generated_count`åŸºäºåºåˆ—é•¿åº¦
2. âœ… `char_count`åªè®¡ç®—æ–°ç”Ÿæˆéƒ¨åˆ†

**ç»“æœ**ï¼šåº”è¯¥èƒ½æ­£ç¡®ç”Ÿæˆ2-3å¥è¯

---

## æ€»ç»“

### é—®é¢˜é“¾

```
V4: åªæœ‰1å¥è¯
  â†“
V5.0: é…ç½®æ”¹ä¸º2å¥ + 90å­—
  â†“
Bug: generated_countå’Œchar_countè®¡ç®—é”™è¯¯
  â†“
ç»“æœ: é…ç½®æœªç”Ÿæ•ˆï¼Œä»åªæœ‰1å¥
  â†“
V5.1: ä¿®å¤è®¡æ•°bug
  â†“
é¢„æœŸ: æ­£ç¡®ç”Ÿæˆ2-3å¥è¯ âœ…
```

### æ ¸å¿ƒä¿®å¤

**ä¹‹å‰**ï¼š
- `generated_count += 1` â†’ è®¡æ•°è°ƒç”¨æ¬¡æ•°ï¼ˆé”™è¯¯ï¼‰
- `decode(input_ids[0])` â†’ åŒ…å«promptï¼ˆé”™è¯¯ï¼‰

**ç°åœ¨**ï¼š
- `generated_count = length - initial_length` â†’ è®¡æ•°å®é™…tokensï¼ˆæ­£ç¡®ï¼‰
- `decode(input_ids[0, initial_length:])` â†’ åªè®¡ç®—ç”Ÿæˆéƒ¨åˆ†ï¼ˆæ­£ç¡®ï¼‰

---

## æµ‹è¯•å»ºè®®

è¿è¡Œæµ‹è¯•ï¼Œåº”è¯¥çœ‹åˆ°ï¼š
- âœ… å¹³å‡tokens: 80-120ï¼ˆä»41.7å¤§å¹…æå‡ï¼‰
- âœ… å¥å­æ•°: 2-3ï¼ˆä»1æå‡ï¼‰
- âœ… å­—ç¬¦æ•°: 90-140ï¼ˆä»~65æå‡ï¼‰
- âœ… æ—¥å¿—ä¸­æœ‰"Not enough characters, continuing"çš„ä¿¡æ¯
- âœ… æ—¥å¿—ä¸­æœ€ç»ˆ"All conditions met, stopping"æ—¶å­—ç¬¦æ•°â‰¥90

**å‘½ä»¤**ï¼š
```bash
python experiments/runs/run_speculative_decoding_cpu_limited.py \
    --dataset_type unified \
    --dataset_path data/processed/mer2024/manifest_audio_only_final.json \
    --caption_type audio_only \
    --language chinese \
    --prompt_type detailed \
    --max_samples 10
```

---

**è¿™æ¬¡åº”è¯¥èƒ½çœŸæ­£å®ç°2-3å¥è¯çš„è¾“å‡ºäº†ï¼** ğŸ‰


