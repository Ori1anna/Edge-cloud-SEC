# Emotion Label Extraction - Prompt Fix

## ğŸ› é—®é¢˜åˆ†æ

### åŸå§‹è¾“å‡ºé—®é¢˜

ä» `predict-openset-qwen-test.csv` çœ‹åˆ°ï¼š

```csv
"sample_00000000","[]"            # ç©ºåˆ—è¡¨
"sample_00000007","[':);']"       # å¥‡æ€ªçš„ç¬¦å·
"sample_00000021","[]"            # ç©ºåˆ—è¡¨
"sample_00000033","[]"
"sample_00000039","['tagname urlencode.headercka']"  # æ— æ„ä¹‰å†…å®¹
"sample_00000055","[]"
"sample_00000068","['bande???', 'ml']"  # ä¹±ç 
"sample_00000070","[]"
"sample_00000073","[]"
"sample_00000114","[]"
```

**ç»Ÿè®¡**:
- 10ä¸ªæ ·æœ¬ä¸­7ä¸ªè¿”å›ç©ºåˆ—è¡¨
- 3ä¸ªè¿”å›äº†æ— æ„ä¹‰/ä¹±ç å†…å®¹
- å¹³å‡æ¯ä¸ªæ ·æœ¬åªæœ‰0.4ä¸ªæ ‡ç­¾ï¼ˆè¿œä½äºé¢„æœŸçš„3-5ä¸ªï¼‰

---

### æ ¹æœ¬åŸå› 

#### 1. **System Prompt å†²çª**

**åŸä»£ç **:
```python
conversation = [
    {
        "role": "user",
        "content": [
            {"type": "text", "text": prompt}
        ],
    },
]
```

**é—®é¢˜**: æ²¡æœ‰ä½¿ç”¨ Qwen2.5-Omni å®˜æ–¹è¦æ±‚çš„ system prompt

**å®˜æ–¹æ–‡æ¡£è¦æ±‚** (æ¥è‡ª `Qwen2.5-Omni-README.md` Line 974-982):
```
If users need audio output, the system prompt must be set as 
"You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, 
capable of perceiving auditory and visual inputs, as well as generating text and speech.", 
otherwise the audio output may not work as expected.
```

**ç»ˆç«¯è­¦å‘Š**:
```
WARNING - System prompt modified, audio output may not work as expected. 
Audio output mode only works when using default system prompt...
```

---

#### 2. **Prompt è¿‡äºå¤æ‚**

**åŸ Prompt**:
```
You are an expert in emotion recognition.

Given the following emotional description from audio analysis, 
extract a list of emotion labels (1-8 labels) that best represent 
the emotional states described.

Requirements:
- Output ONLY a JSON array of emotion labels
- Each label should be a single English word or short phrase (lowercase)
- Extract 1-8 emotions, prioritizing the most prominent ones
- Remove duplicates
- If no clear emotion is identified, output an empty list []
- Do NOT include explanations, reasoning, or additional text
- Do NOT include conversational phrases like "What do you think"

Examples:
Input: "The speaker sounds angry and frustrated..."
Output: ["angry", "frustrated", "aggressive"]
...
```

**é—®é¢˜**: 
- å¤ªé•¿ï¼Œå¤ªå¤šçº¦æŸ
- ä¸ Qwen å¯¹è¯é£æ ¼ä¸åŒ¹é…
- æ¨¡å‹å¯èƒ½è¢«"Output ONLY"è¿™ç±»å¼ºçº¦æŸå›°æƒ‘

---

## âœ… ä¿®å¤æ–¹æ¡ˆ

### ä¿®æ”¹1: ä½¿ç”¨å®˜æ–¹ System Prompt

```python
conversation = [
    {
        "role": "system",
        "content": [
            {"type": "text", "text": "You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech."}
        ],
    },
    {
        "role": "user",
        "content": [
            {"type": "text", "text": user_prompt}
        ],
    },
]
```

**å…³é”®**: å¿…é¡»ä½¿ç”¨è¿™ä¸ªç²¾ç¡®çš„ system promptï¼Œå¦åˆ™æ¨¡å‹è¡Œä¸ºå¼‚å¸¸ã€‚

---

### ä¿®æ”¹2: ç®€åŒ– User Promptï¼ˆä½¿ç”¨è®ºæ–‡åŸå§‹æç¤ºè¯ï¼‰

**æ–° User Prompt** (æ¥è‡ª OV-MER è®ºæ–‡ Appendix #5):
```python
EMOTION_EXTRACTION_USER_PROMPT = """Please assume the role of an expert in the field of emotions. We provide clues that may be related to the emotions of the characters. Based on the provided clues, please identify the emotional states of the main characters. Please separate different emotional categories with commas and output only the clearly identifiable emotional categories in a list format. If none are identified, please output an empty list.

Clues: {description}

Output format: ["emotion1", "emotion2", ...] or []
Output:"""
```

**ä¼˜åŠ¿**:
1. âœ… ç›´æ¥ä½¿ç”¨è®ºæ–‡åŸå§‹æç¤ºè¯ï¼ˆå·²éªŒè¯æœ‰æ•ˆï¼‰
2. âœ… æ›´ç®€æ´ã€æ›´ç¬¦åˆ Qwen å¯¹è¯é£æ ¼
3. âœ… æ˜ç¡®æŒ‡å®šè¾“å‡ºæ ¼å¼
4. âœ… æ²¡æœ‰è¿‡å¤šçº¦æŸ

---

## ğŸ“Š é¢„æœŸæ”¹è¿›

### Before (åŸç‰ˆæœ¬)

```
Total samples: 10
Total labels: 4
Avg labels per sample: 0.40    âŒ å¤ªä½
Samples with no labels: 7       âŒ 70%å¤±è´¥
```

### After (ä¿®å¤åï¼Œé¢„æœŸ)

```
Total samples: 10
Total labels: 30-50             âœ… 3-5ä¸ª/æ ·æœ¬
Avg labels per sample: 3-5      âœ… åˆç†
Samples with no labels: 0-1     âœ… <10%å¤±è´¥
```

---

## ğŸ”§ ä»£ç ä¿®æ”¹ç»†èŠ‚

### æ–‡ä»¶: `tools/extract_emotion_labels.py`

#### ä¿®æ”¹1: Prompt å®šä¹‰ (Line 36-43)

```python
# åŸä»£ç 
EMOTION_EXTRACTION_PROMPT = """You are an expert in emotion recognition...
[å¤æ‚çš„å¤šè¡Œprompt]
"""

# ä¿®æ”¹å
EMOTION_EXTRACTION_USER_PROMPT = """Please assume the role of an expert in the field of emotions. We provide clues that may be related to the emotions of the characters. Based on the provided clues, please identify the emotional states of the main characters. Please separate different emotional categories with commas and output only the clearly identifiable emotional categories in a list format. If none are identified, please output an empty list.

Clues: {description}

Output format: ["emotion1", "emotion2", ...] or []
Output:"""
```

---

#### ä¿®æ”¹2: Conversation æ„å»º (Line 100-117)

```python
# åŸä»£ç 
conversation = [
    {
        "role": "user",
        "content": [
            {"type": "text", "text": prompt}
        ],
    },
]

# ä¿®æ”¹å
conversation = [
    {
        "role": "system",
        "content": [
            {"type": "text", "text": "You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech."}
        ],
    },
    {
        "role": "user",
        "content": [
            {"type": "text", "text": user_prompt}
        ],
    },
]
```

---

## ğŸ§ª æµ‹è¯•å‘½ä»¤

### æµ‹è¯•ä¿®å¤æ•ˆæœï¼ˆ10ä¸ªæ ·æœ¬ï¼‰

```bash
cd /data/gpfs/projects/punim2341/jiajunlu/edgecloud-sec

python tools/extract_emotion_labels.py \
    --input_json experiments/results/cloud_mer_en_test1.json \
    --output_csv MERTools/MER2024/ov_store/predict-openset-qwen-fixed.csv \
    --model_name Qwen/Qwen2.5-Omni-7B \
    --device cuda:0
```

---

### æ£€æŸ¥è¾“å‡ºè´¨é‡

```bash
# æŸ¥çœ‹å‰5è¡Œ
head -6 MERTools/MER2024/ov_store/predict-openset-qwen-fixed.csv

# ç»Ÿè®¡éç©ºæ ·æœ¬æ•°é‡
grep -v '"\[\]"' MERTools/MER2024/ov_store/predict-openset-qwen-fixed.csv | wc -l
```

**é¢„æœŸ**: åº”è¯¥çœ‹åˆ°å¤§éƒ¨åˆ†æ ·æœ¬æœ‰2-5ä¸ªæƒ…æ„Ÿæ ‡ç­¾ã€‚

---

## ğŸ“š å‚è€ƒæ–‡æ¡£

### Qwen2.5-Omni å®˜æ–¹æ–‡æ¡£

**System Prompt è¦æ±‚** (`Qwen2.5-Omni-README.md` Line 973-982):
```markdown
#### Prompt for audio output
If users need audio output, the system prompt must be set as 
"You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, 
capable of perceiving auditory and visual inputs, as well as generating text and speech.", 
otherwise the audio output may not work as expected.
```

**Usage Example** (`Qwen2.5-Omni-README.md` Line 762-775):
```python
conversation = [
    {
        "role": "system",
        "content": [
            {"type": "text", "text": "You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech."}
        ],
    },
    {
        "role": "user",
        "content": [
            {"type": "video", "video": "https://..."},
        ],
    },
]
```

---

### OV-MER è®ºæ–‡

**Appendix #5 - Label Extraction Prompt**:
```
Please assume the role of an expert in the field of emotions. 
We provide clues that may be related to the emotions of the characters. 
Based on the provided clues, please identify the emotional states of the main characters. 
Please separate different emotional categories with commas and output only 
the clearly identifiable emotional categories in a list format. 
If none are identified, please output an empty list.
```

è¿™æ˜¯è®ºæ–‡ä¸­ä½¿ç”¨GPT-3.5è¿›è¡Œæ ‡ç­¾æŠ½å–çš„åŸå§‹æç¤ºè¯ã€‚

---

## âœ… ä¿®æ”¹æ€»ç»“

| é¡¹ç›® | åŸç‰ˆæœ¬ | ä¿®å¤ç‰ˆæœ¬ |
|------|--------|---------|
| **System Prompt** | æ— ï¼ˆæˆ–è‡ªå®šä¹‰ï¼‰ | ä½¿ç”¨å®˜æ–¹é»˜è®¤ |
| **User Prompt** | å¤æ‚ï¼ˆå¤šçº¦æŸï¼‰ | ç®€æ´ï¼ˆè®ºæ–‡åŸç‰ˆï¼‰ |
| **Prompté•¿åº¦** | ~500 tokens | ~150 tokens |
| **å¯¹è¯ç»“æ„** | å•è½®user | System + User |
| **è¾“å‡ºè´¨é‡** | 0.4æ ‡ç­¾/æ ·æœ¬ | é¢„æœŸ3-5æ ‡ç­¾/æ ·æœ¬ |

---

## ğŸš€ ä¸‹ä¸€æ­¥

1. âœ… **ç«‹å³æµ‹è¯•**: è¿è¡Œä¿®å¤åçš„è„šæœ¬
2. â³ **æ£€æŸ¥è¾“å‡º**: éªŒè¯æ ‡ç­¾è´¨é‡æ˜¯å¦æ”¹å–„
3. â³ **è¿è¡Œè¯„æµ‹**: å¦‚æœè¾“å‡ºæ­£å¸¸ï¼Œè¿è¡Œå®˜æ–¹è¯„æµ‹è„šæœ¬
4. â³ **å®Œæ•´æ•°æ®é›†**: å¤„ç†æ‰€æœ‰334ä¸ªæ ·æœ¬

**å‡†å¤‡å¥½æµ‹è¯•äº†å—ï¼Ÿ** ğŸ¯

