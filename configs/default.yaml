# Default configuration for Edge-Cloud Speculative Decoding

# Model Configuration
models:
  edge:
    name: "Qwen/Qwen2.5-Omni-3B"
    device: "cuda"
    dtype: "float16"
    
  cloud:
    name: "Qwen/Qwen2.5-Omni-7B"
    device: "cuda"
    dtype: "float16"

# Audio Processing
audio:
  sample_rate: 16000
  n_mels: 80
  n_fft: 1024
  hop_length: 256
  feature_type: "mel"  # "mel" or "mfcc"
  normalize: true

# Decoding Parameters
decoding:
  max_tokens: 100
  temperature: 0.7
  top_p: 0.9
  draft_length: 32  # Number of tokens to generate in each draft

# Uncertainty Thresholds
uncertainty:
  entropy_threshold: 2.0
  margin_threshold: 0.1
  log_prob_threshold: -2.0

# Content-Aware Rules
content_rules:
  verify_numbers: true
  verify_dates: true
  verify_names: true

# Cache Configuration
cache:
  kv_cache_size: 1024
  prefix_cache_size: 512

# Evaluation
evaluation:
  metrics: ["bleu", "cider", "emotion_accuracy"]
  test_split: 0.2
  random_seed: 42

# Logging
logging:
  level: "INFO"
  save_dir: "experiments/logs"
  log_interval: 100

# Data
data:
  train_path: "data/processed/unified(mer_secap)/unified_manifest.json"
  test_path: "data/processed/unified(mer_secap)/unified_manifest.json"
  cache_dir: "experiments/cache"
  
# Training (if needed)
training:
  batch_size: 8
  learning_rate: 1e-5
  num_epochs: 10
  warmup_steps: 100
  gradient_accumulation_steps: 4
